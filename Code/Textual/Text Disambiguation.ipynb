{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b5241f-fe9b-48df-b6b1-6ca664a59599",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bb2a73-153d-451d-99ac-697475499838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef43bea-7ac8-4ee2-9028-ad6fb76b6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CUDA usage\n",
    "os.environ[\"OLLAMA_BACKEND\"] = \"cuda\"\n",
    "os.environ[\"OLLAMA_NUM_THREADS\"] = \"16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731a0ec-a4f9-4bbf-adeb-17d4c5072ff9",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef190f-20d4-428f-9e03-ea536d500680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models\n",
    "ml_models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42, max_iter=1000)), # 2 sec\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)), # 2 min\n",
    "    ('SVM', SVC(random_state=42)), # 30 min\n",
    "    ('KNN', KNeighborsClassifier()), # 30 sec\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)) # 30 sec\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3761f59a-3a86-40af-8212-f69a6cb24662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMs\n",
    "models = ['llama3.2:1b', 'llama3.2:3b', 'llama3.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7115fa55-4512-40a2-81cf-8e90da1ff251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize (Bag of words representation)\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353a9cc1-174b-4281-a056-96695636d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows that LLM will generate and compare to\n",
    "n_rows = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f24e8-5e1c-430e-a4a7-6915ee2f4f4d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56eb007d-89fb-4404-8464-8b7a6e833bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.\\nThe first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.\\nIt is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.\\nI would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. \\nThe filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. \\nThe actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. \\nThe realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.\\nThis was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.\\nThis may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.\\nThis movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.\\nOK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.\\n3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. \\nThis being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.\\nThe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.\\nThe acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.\\nWe wish Mr. Mattei good luck and await anxiously for his next work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.\\nThe first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.\\nIt is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.\\nI would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A wonderful little production. \\nThe filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. \\nThe actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. \\nThe realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.\\nThis was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.\\nThis may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.\\nThis movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.\\nOK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.\\n3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. \\nThis being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.\\nThe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.\\nThe acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.\\nWe wish Mr. Mattei good luck and await anxiously for his next work.   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "base_df = pd.read_csv('IMB_preprocessed_2025_04_06.csv')\n",
    "\n",
    "# We want to be able to read the full reviews\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "# Display the first 5 records\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbfa71e-8283-480c-addb-a76c8846d9a5",
   "metadata": {},
   "source": [
    "# Experimential setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0549bb44-636f-4bb0-a51e-fe24509c9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimental_setup(df):\n",
    "    # Split into X and y\n",
    "    X = df['review']\n",
    "    y = df['sentiment']\n",
    "    \n",
    "    # Split data into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Only train on the first n_rows\n",
    "    X_train = X_train[:n_rows]\n",
    "    y_train = y_train[:n_rows]\n",
    "\n",
    "    # Transform text reviews to Bag of Words representation\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Print the shapes of the sets\n",
    "    print(f\"Training Set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}\")\n",
    "    print(f\"Test Set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}\")\n",
    "    print()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019c0e5-8fe1-412b-9194-f8956fc72b6f",
   "metadata": {},
   "source": [
    "# Modeling and Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8478aeaf-2f61-41cd-9a89-2ab05ecde41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models with multiple metrics\n",
    "def evaluate_models_with_metrics(models, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "\n",
    "    for name, model in models:      \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Store results for the model\n",
    "        model_results = {\n",
    "            'Model': name,\n",
    "            'Test Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'Test Precision': precision_score(y_test, y_test_pred),\n",
    "            'Test Recall': recall_score(y_test, y_test_pred),\n",
    "            'Test F1-Score': f1_score(y_test, y_test_pred)\n",
    "        }\n",
    "        \n",
    "        results.append(model_results)\n",
    "\n",
    "    # Convert results to a pandas DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab39a7e-8b3f-4e4b-a4ca-e19eb77e3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: X_train shape = (3000, 10000), y_train shape = (3000,)\n",
      "Test Set: X_test shape = (10000, 10000), y_test shape = (10000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.851955</td>\n",
       "      <td>0.840200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.809659</td>\n",
       "      <td>0.851756</td>\n",
       "      <td>0.830174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.833674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.581309</td>\n",
       "      <td>0.588807</td>\n",
       "      <td>0.585034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.761314</td>\n",
       "      <td>0.864656</td>\n",
       "      <td>0.809701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Test Accuracy  Test Precision  Test Recall  \\\n",
       "0  Logistic Regression         0.8367        0.828764     0.851955   \n",
       "1        Random Forest         0.8244        0.809659     0.851756   \n",
       "2                  SVM         0.8210        0.783855     0.890256   \n",
       "3                  KNN         0.5791        0.581309     0.588807   \n",
       "4    Gradient Boosting         0.7952        0.761314     0.864656   \n",
       "\n",
       "   Test F1-Score  \n",
       "0       0.840200  \n",
       "1       0.830174  \n",
       "2       0.833674  \n",
       "3       0.585034  \n",
       "4       0.809701  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the split\n",
    "X_train_base, y_train_base, X_test_base, y_test_base = experimental_setup(base_df)\n",
    "\n",
    "# Evaluate models with multiple metrics and print results\n",
    "base_results = evaluate_models_with_metrics(ml_models, X_train_base, y_train_base, X_test_base, y_test_base)\n",
    "display(base_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ac430-5af4-4a83-84ff-ec24c16bea25",
   "metadata": {},
   "source": [
    "# Data Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9491d9f-5ae9-4a8b-9fcf-acd52860ac0c",
   "metadata": {},
   "source": [
    "### Non-Qualitative loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19bb1992-5174-4b91-be38-e46f33d727f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = '''''Clarify any ambiguous phrases in the following review to make the meaning more precise, but do not alter the original meaning of the review. \n",
    "Return only the disambiguated text, do not return any explanations or additional commentary.\n",
    "\n",
    "Review:\n",
    "{review}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "719de34f-fec8-4380-bd9b-510313c4c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llama3.2:1b (Model 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disambiguating rows: 100%|███████████████████████████████████████████████████████| 3000/3000 [3:56:58<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llama3.2:3b (Model 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disambiguating rows: 100%|███████████████████████████████████████████████████████| 3000/3000 [7:10:17<00:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llama3.1 (Model 3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disambiguating rows: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [30:13:06<00:00, 36.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store results per model\n",
    "model_list = {}\n",
    "\n",
    "# Important! You must only sample from the train set, you mustn't sample from the test set\n",
    "# This is to prevent data leakage\n",
    "X_train, _, y_train, _ = train_test_split(base_df['review'], base_df['sentiment'], test_size=0.2, random_state=42)\n",
    "llm_train_df = pd.DataFrame({'review': X_train, 'sentiment': y_train})\n",
    "\n",
    "# Iterate through models\n",
    "for index, model in enumerate(models):\n",
    "    print(\"Processing Model: \" + model + \" (Model \" + str(index + 1) + \"/\" + str(len(models)) + \")\")\n",
    "    model_list[model] = []\n",
    "\n",
    "    # Disambiguate n_rows\n",
    "    for index, row in tqdm(llm_train_df[:n_rows].iterrows(), total=n_rows, desc=\"Disambiguating rows\"):\n",
    "        # Format the prompt baesd on the row\n",
    "        formatted_prompt = prompt.format(review=row['review'])\n",
    "\n",
    "        # Disambiguate\n",
    "        response = ollama.generate(model=model, prompt=formatted_prompt)['response']\n",
    "\n",
    "        # Store response and target variable\n",
    "        model_list[model].append([response, row['sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5b15a-c6d5-436f-b701-d83ff3dd7ad0",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ceaa149-2d8f-47ea-8e66-5218dd952c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(base_df, llm_df):\n",
    "    # Set 'Model' as the index in DataFrames\n",
    "    base_df_results = base_df.set_index('Model')\n",
    "    llm_df_results = llm_df.set_index('Model')\n",
    "    \n",
    "    # Rename evaluation metrics columns\n",
    "    base_df_results = base_df_results.rename(columns={\n",
    "        'Test Accuracy': 'Test Accuracy base', 'Test F1-Score': 'Test F1-Score base',\n",
    "        'Test Precision': 'Test Precision base', 'Test Recall': 'Test Recall base'\n",
    "    })\n",
    "\n",
    "    llm_df_results = llm_df_results.rename(columns={\n",
    "        'Test Accuracy': 'Test Accuracy llm altered', 'Test F1-Score': 'Test F1-Score llm altered',\n",
    "        'Test Precision': 'Test Precision llm altered', 'Test Recall': 'Test Recall llm altered'\n",
    "    })\n",
    "    \n",
    "    # Merge dfs by index\n",
    "    raw_final_results = base_df_results.join(llm_df_results)\n",
    "\n",
    "    # Show raw data results\n",
    "    print(\"Raw performance metrics:\")\n",
    "    display(raw_final_results)\n",
    "    \n",
    "    # Calculate and display the difference matrix (% difference)\n",
    "    diff_df = pd.DataFrame()\n",
    "    diff_df['Test Accuracy % diff'] = round(((raw_final_results['Test Accuracy llm altered'] - raw_final_results['Test Accuracy base']) \n",
    "                                                   / raw_final_results['Test Accuracy base']) * 100, 1)\n",
    "    diff_df['Test F1-Score % diff'] = round(((raw_final_results['Test F1-Score llm altered'] - raw_final_results['Test F1-Score base']) \n",
    "                                                 / raw_final_results['Test F1-Score base']) * 100, 1)\n",
    "    diff_df['Test Precision % diff'] = round(((raw_final_results['Test Precision llm altered'] - raw_final_results['Test Precision base']) \n",
    "                                           / raw_final_results['Test Precision base']) * 100, 1)\n",
    "    diff_df['Test Recall % diff'] = round(((raw_final_results['Test Recall llm altered'] - raw_final_results['Test Recall base']) \n",
    "                                           / raw_final_results['Test Recall base']) * 100, 1)\n",
    "    print(\"% Difference df (between base and LLM altered df):\")\n",
    "    display(diff_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8360f6d-cb1a-4a40-b92d-33822b2fe211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llama3.2:1b (Model 1/3)\n",
      "Training Set: X_train shape = (3000, 10000), y_train shape = (3000,)\n",
      "Test Set: X_test shape = (10000, 10000), y_test shape = (10000,)\n",
      "\n",
      "Raw performance metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy base</th>\n",
       "      <th>Test Precision base</th>\n",
       "      <th>Test Recall base</th>\n",
       "      <th>Test F1-Score base</th>\n",
       "      <th>Test Accuracy llm altered</th>\n",
       "      <th>Test Precision llm altered</th>\n",
       "      <th>Test Recall llm altered</th>\n",
       "      <th>Test F1-Score llm altered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.851955</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.818252</td>\n",
       "      <td>0.841635</td>\n",
       "      <td>0.829779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.809659</td>\n",
       "      <td>0.851756</td>\n",
       "      <td>0.830174</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.799703</td>\n",
       "      <td>0.855725</td>\n",
       "      <td>0.826766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.833674</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.601985</td>\n",
       "      <td>0.962889</td>\n",
       "      <td>0.740820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.581309</td>\n",
       "      <td>0.588807</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.607958</td>\n",
       "      <td>0.184957</td>\n",
       "      <td>0.283628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.761314</td>\n",
       "      <td>0.864656</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.770138</td>\n",
       "      <td>0.855725</td>\n",
       "      <td>0.810679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy base  Test Precision base  \\\n",
       "Model                                                          \n",
       "Logistic Regression              0.8367             0.828764   \n",
       "Random Forest                    0.8244             0.809659   \n",
       "SVM                              0.8210             0.783855   \n",
       "KNN                              0.5791             0.581309   \n",
       "Gradient Boosting                0.7952             0.761314   \n",
       "\n",
       "                     Test Recall base  Test F1-Score base  \\\n",
       "Model                                                       \n",
       "Logistic Regression          0.851955            0.840200   \n",
       "Random Forest                0.851756            0.830174   \n",
       "SVM                          0.890256            0.833674   \n",
       "KNN                          0.588807            0.585034   \n",
       "Gradient Boosting            0.864656            0.809701   \n",
       "\n",
       "                     Test Accuracy llm altered  Test Precision llm altered  \\\n",
       "Model                                                                        \n",
       "Logistic Regression                     0.8260                    0.818252   \n",
       "Random Forest                           0.8193                    0.799703   \n",
       "SVM                                     0.6605                    0.601985   \n",
       "KNN                                     0.5292                    0.607958   \n",
       "Gradient Boosting                       0.7986                    0.770138   \n",
       "\n",
       "                     Test Recall llm altered  Test F1-Score llm altered  \n",
       "Model                                                                    \n",
       "Logistic Regression                 0.841635                   0.829779  \n",
       "Random Forest                       0.855725                   0.826766  \n",
       "SVM                                 0.962889                   0.740820  \n",
       "KNN                                 0.184957                   0.283628  \n",
       "Gradient Boosting                   0.855725                   0.810679  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Difference df (between base and LLM altered df):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy % diff</th>\n",
       "      <th>Test F1-Score % diff</th>\n",
       "      <th>Test Precision % diff</th>\n",
       "      <th>Test Recall % diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>-19.5</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-23.2</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>-8.6</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy % diff  Test F1-Score % diff  \\\n",
       "Model                                                             \n",
       "Logistic Regression                  -1.3                  -1.2   \n",
       "Random Forest                        -0.6                  -0.4   \n",
       "SVM                                 -19.5                 -11.1   \n",
       "KNN                                  -8.6                 -51.5   \n",
       "Gradient Boosting                     0.4                   0.1   \n",
       "\n",
       "                     Test Precision % diff  Test Recall % diff  \n",
       "Model                                                           \n",
       "Logistic Regression                   -1.3                -1.2  \n",
       "Random Forest                         -1.2                 0.5  \n",
       "SVM                                  -23.2                 8.2  \n",
       "KNN                                    4.6               -68.6  \n",
       "Gradient Boosting                      1.2                -1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Model: llama3.2:3b (Model 2/3)\n",
      "Training Set: X_train shape = (3000, 10000), y_train shape = (3000,)\n",
      "Test Set: X_test shape = (10000, 10000), y_test shape = (10000,)\n",
      "\n",
      "Raw performance metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy base</th>\n",
       "      <th>Test Precision base</th>\n",
       "      <th>Test Recall base</th>\n",
       "      <th>Test F1-Score base</th>\n",
       "      <th>Test Accuracy llm altered</th>\n",
       "      <th>Test Precision llm altered</th>\n",
       "      <th>Test Recall llm altered</th>\n",
       "      <th>Test F1-Score llm altered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.851955</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.828495</td>\n",
       "      <td>0.855130</td>\n",
       "      <td>0.841602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.809659</td>\n",
       "      <td>0.851756</td>\n",
       "      <td>0.830174</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.820503</td>\n",
       "      <td>0.854535</td>\n",
       "      <td>0.837173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.833674</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.784786</td>\n",
       "      <td>0.886485</td>\n",
       "      <td>0.832541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.581309</td>\n",
       "      <td>0.588807</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.586222</td>\n",
       "      <td>0.261758</td>\n",
       "      <td>0.361915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.761314</td>\n",
       "      <td>0.864656</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.765495</td>\n",
       "      <td>0.860290</td>\n",
       "      <td>0.810129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy base  Test Precision base  \\\n",
       "Model                                                          \n",
       "Logistic Regression              0.8367             0.828764   \n",
       "Random Forest                    0.8244             0.809659   \n",
       "SVM                              0.8210             0.783855   \n",
       "KNN                              0.5791             0.581309   \n",
       "Gradient Boosting                0.7952             0.761314   \n",
       "\n",
       "                     Test Recall base  Test F1-Score base  \\\n",
       "Model                                                       \n",
       "Logistic Regression          0.851955            0.840200   \n",
       "Random Forest                0.851756            0.830174   \n",
       "SVM                          0.890256            0.833674   \n",
       "KNN                          0.588807            0.585034   \n",
       "Gradient Boosting            0.864656            0.809701   \n",
       "\n",
       "                     Test Accuracy llm altered  Test Precision llm altered  \\\n",
       "Model                                                                        \n",
       "Logistic Regression                     0.8378                    0.828495   \n",
       "Random Forest                           0.8325                    0.820503   \n",
       "SVM                                     0.8203                    0.784786   \n",
       "KNN                                     0.5349                    0.586222   \n",
       "Gradient Boosting                       0.7968                    0.765495   \n",
       "\n",
       "                     Test Recall llm altered  Test F1-Score llm altered  \n",
       "Model                                                                    \n",
       "Logistic Regression                 0.855130                   0.841602  \n",
       "Random Forest                       0.854535                   0.837173  \n",
       "SVM                                 0.886485                   0.832541  \n",
       "KNN                                 0.261758                   0.361915  \n",
       "Gradient Boosting                   0.860290                   0.810129  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Difference df (between base and LLM altered df):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy % diff</th>\n",
       "      <th>Test F1-Score % diff</th>\n",
       "      <th>Test Precision % diff</th>\n",
       "      <th>Test Recall % diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>-7.6</td>\n",
       "      <td>-38.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy % diff  Test F1-Score % diff  \\\n",
       "Model                                                             \n",
       "Logistic Regression                   0.1                   0.2   \n",
       "Random Forest                         1.0                   0.8   \n",
       "SVM                                  -0.1                  -0.1   \n",
       "KNN                                  -7.6                 -38.1   \n",
       "Gradient Boosting                     0.2                   0.1   \n",
       "\n",
       "                     Test Precision % diff  Test Recall % diff  \n",
       "Model                                                           \n",
       "Logistic Regression                   -0.0                 0.4  \n",
       "Random Forest                          1.3                 0.3  \n",
       "SVM                                    0.1                -0.4  \n",
       "KNN                                    0.8               -55.5  \n",
       "Gradient Boosting                      0.5                -0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Model: llama3.1 (Model 3/3)\n",
      "Training Set: X_train shape = (3000, 10000), y_train shape = (3000,)\n",
      "Test Set: X_test shape = (10000, 10000), y_test shape = (10000,)\n",
      "\n",
      "Raw performance metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy base</th>\n",
       "      <th>Test Precision base</th>\n",
       "      <th>Test Recall base</th>\n",
       "      <th>Test F1-Score base</th>\n",
       "      <th>Test Accuracy llm altered</th>\n",
       "      <th>Test Precision llm altered</th>\n",
       "      <th>Test Recall llm altered</th>\n",
       "      <th>Test F1-Score llm altered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.851955</td>\n",
       "      <td>0.840200</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.819073</td>\n",
       "      <td>0.862473</td>\n",
       "      <td>0.840213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.809659</td>\n",
       "      <td>0.851756</td>\n",
       "      <td>0.830174</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.812123</td>\n",
       "      <td>0.856122</td>\n",
       "      <td>0.833543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>0.890256</td>\n",
       "      <td>0.833674</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.787680</td>\n",
       "      <td>0.880532</td>\n",
       "      <td>0.831522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.581309</td>\n",
       "      <td>0.588807</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.607174</td>\n",
       "      <td>0.137726</td>\n",
       "      <td>0.224523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.761314</td>\n",
       "      <td>0.864656</td>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.757268</td>\n",
       "      <td>0.873586</td>\n",
       "      <td>0.811279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy base  Test Precision base  \\\n",
       "Model                                                          \n",
       "Logistic Regression              0.8367             0.828764   \n",
       "Random Forest                    0.8244             0.809659   \n",
       "SVM                              0.8210             0.783855   \n",
       "KNN                              0.5791             0.581309   \n",
       "Gradient Boosting                0.7952             0.761314   \n",
       "\n",
       "                     Test Recall base  Test F1-Score base  \\\n",
       "Model                                                       \n",
       "Logistic Regression          0.851955            0.840200   \n",
       "Random Forest                0.851756            0.830174   \n",
       "SVM                          0.890256            0.833674   \n",
       "KNN                          0.588807            0.585034   \n",
       "Gradient Boosting            0.864656            0.809701   \n",
       "\n",
       "                     Test Accuracy llm altered  Test Precision llm altered  \\\n",
       "Model                                                                        \n",
       "Logistic Regression                     0.8347                    0.819073   \n",
       "Random Forest                           0.8277                    0.812123   \n",
       "SVM                                     0.8202                    0.787680   \n",
       "KNN                                     0.5206                    0.607174   \n",
       "Gradient Boosting                       0.7952                    0.757268   \n",
       "\n",
       "                     Test Recall llm altered  Test F1-Score llm altered  \n",
       "Model                                                                    \n",
       "Logistic Regression                 0.862473                   0.840213  \n",
       "Random Forest                       0.856122                   0.833543  \n",
       "SVM                                 0.880532                   0.831522  \n",
       "KNN                                 0.137726                   0.224523  \n",
       "Gradient Boosting                   0.873586                   0.811279  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Difference df (between base and LLM altered df):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy % diff</th>\n",
       "      <th>Test F1-Score % diff</th>\n",
       "      <th>Test Precision % diff</th>\n",
       "      <th>Test Recall % diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>-10.1</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Test Accuracy % diff  Test F1-Score % diff  \\\n",
       "Model                                                             \n",
       "Logistic Regression                  -0.2                   0.0   \n",
       "Random Forest                         0.4                   0.4   \n",
       "SVM                                  -0.1                  -0.3   \n",
       "KNN                                 -10.1                 -61.6   \n",
       "Gradient Boosting                     0.0                   0.2   \n",
       "\n",
       "                     Test Precision % diff  Test Recall % diff  \n",
       "Model                                                           \n",
       "Logistic Regression                   -1.2                 1.2  \n",
       "Random Forest                          0.3                 0.5  \n",
       "SVM                                    0.5                -1.1  \n",
       "KNN                                    4.4               -76.6  \n",
       "Gradient Boosting                     -0.5                 1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through models\n",
    "for index, model in enumerate(models):\n",
    "    print(\"Processing Model: \" + model + \" (Model \" + str(index + 1) + \"/\" + str(len(models)) + \")\")\n",
    "\n",
    "    # Get data and make a DataFrame\n",
    "    disambiguation_df = pd.DataFrame(model_list[model], columns=['review', 'sentiment'])\n",
    "\n",
    "    # Split into X and y\n",
    "    X_train_disambiguation = disambiguation_df['review']\n",
    "    y_train_disambiguation = disambiguation_df['sentiment']\n",
    "\n",
    "    # Get original test set\n",
    "    _, X_test_base, _, y_test_base = train_test_split(base_df['review'], base_df['sentiment'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Transform text reviews to Bag of Words representation\n",
    "    X_train_disambiguation = vectorizer.fit_transform(X_train_disambiguation)\n",
    "    X_test_base = vectorizer.transform(X_test_base)\n",
    "\n",
    "    # Print the shapes of the sets\n",
    "    print(f\"Training Set: X_train shape = {X_train_disambiguation.shape}, y_train shape = {y_train_disambiguation.shape}\")\n",
    "    print(f\"Test Set: X_test shape = {X_test_base.shape}, y_test shape = {y_test_base.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # Evaluate models with multiple metrics and display results\n",
    "    results_disambiguation = evaluate_models_with_metrics(ml_models, X_train_disambiguation, y_train_disambiguation, X_test_base, y_test_base)\n",
    "    \n",
    "    # Compare the results between base and LLM altered df\n",
    "    compare(base_results, results_disambiguation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
