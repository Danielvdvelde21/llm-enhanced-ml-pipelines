{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a29a8-299e-40e1-a74e-1582d18d83fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82983fac-5b01-4856-b440-abbcf7104c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953fb9cb-aaa9-4aaf-8b8b-50dda9f6c027",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f9e379-25a3-4bc1-bcba-49ee832a2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN params\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdb00-4a1f-4d9b-b80e-226d6ae20a8a",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7925995f-a0fc-4c5e-b4cb-cf5c6f6961c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"houses_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6ea717-4682-452a-b90b-23e0829fed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.500387</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-1.424855</td>\n",
       "      <td>228500</td>\n",
       "      <td>houses_preprocessed/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.574868</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.340002</td>\n",
       "      <td>273950</td>\n",
       "      <td>houses_preprocessed/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.500387</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.064963</td>\n",
       "      <td>350000</td>\n",
       "      <td>houses_preprocessed/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.438092</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.363878</td>\n",
       "      <td>385100</td>\n",
       "      <td>houses_preprocessed/4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.500387</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.064963</td>\n",
       "      <td>350000</td>\n",
       "      <td>houses_preprocessed/5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_citi       bed      bath      sqft   price                      image\n",
       "0 -1.500387 -0.489366 -0.472771 -1.424855  228500  houses_preprocessed/1.jpg\n",
       "1 -0.574868 -0.489366 -1.515838 -1.340002  273950  houses_preprocessed/2.jpg\n",
       "2 -1.500387 -0.489366 -1.515838 -1.064963  350000  houses_preprocessed/3.jpg\n",
       "3 -1.438092  0.477001  0.570296  0.363878  385100  houses_preprocessed/4.jpg\n",
       "4 -1.500387 -0.489366 -1.515838 -1.064963  350000  houses_preprocessed/5.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3552c-6833-4e2b-a86c-53ac85c24404",
   "metadata": {},
   "source": [
    "# Experimental set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2e59f5-3021-4793-a5ae-ddd8934f923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Tabular features: (12237, 4)\n",
      "Image features: (12237,)\n",
      "Target prices: (12237,)\n",
      "\n",
      "Test Data Shapes:\n",
      "Tabular features: (3060, 4)\n",
      "Image features: (3060,)\n",
      "Target prices: (3060,)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['price'], axis=1), df['price'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, separate tabular and image data for each split\n",
    "X_train_tab = X_train.drop(['image'], axis=1).values # np\n",
    "X_train_img = X_train['image'] # pd \n",
    "\n",
    "X_test_tab = X_test.drop(['image'], axis=1).values # np\n",
    "X_test_img = X_test['image'] # pd \n",
    "\n",
    "# Print shapes\n",
    "print(\"Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab.shape}\")\n",
    "print(f\"Image features: {X_train_img.shape}\")\n",
    "print(f\"Target prices: {y_train.shape}\")\n",
    "print(\"\\nTest Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab.shape}\")\n",
    "print(f\"Image features: {X_test_img.shape}\")\n",
    "print(f\"Target prices: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfed7a8-285e-4881-bfbf-b0454980d6a9",
   "metadata": {},
   "source": [
    "# Modeling and Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6579fe-53d3-4b93-979a-d95806a33946",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e954d389-de34-41e5-9d19-7d9e7b662885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn(input_size_tabular):\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z) # Regression output for price prediction\n",
    "    \n",
    "    nn_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2bf2d2-6655-41ce-a74a-bba745607b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_nn(input_size_tabular):\n",
    "    # Image processing branch with pre-trained ResNet50\n",
    "    res_net = ResNet50(weights='imagenet', include_top=False, input_shape=(311, 415, 3))\n",
    "    \n",
    "    # Unfreeze only the last 10 layers of resnet (fine-tuning) \n",
    "    res_net.trainable = False \n",
    "    for layer in res_net.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = res_net(img_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "    \n",
    "    # Define the model\n",
    "    res_net_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    res_net_model.compile(optimizer='adam', \n",
    "                          loss='mae',\n",
    "                          metrics=['mae', 'R2Score'])\n",
    "   \n",
    "    # Display model summary debug\n",
    "    # res_net_model.summary()\n",
    "\n",
    "    return res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32830c73-97b2-44c6-9628-14031cf58fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, tabular_features, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return (image, tabular_features), label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, tabular_data, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data, labels))\n",
    "    dataset = dataset.map(lambda img, tab, lbl: process_example(img, tab, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(nn, \n",
    "                          X_train_img_paths, X_train_tab, y_train,\n",
    "                          X_test_img_paths, X_test_tab, y_test,\n",
    "                          verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_ds = create_dataset(X_train_img_paths, X_train_tab, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_ds = create_dataset(X_test_img_paths, X_test_tab, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_ds, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404de1b-8b30-48aa-b745-ab81919ca088",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "On just the tabular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e24ebe-7def-4c88-97c2-5e923fbb03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lin_model(model, X_train_tab, y_train, X_test_tab, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_tab, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_test_pred = model.predict(X_test_tab)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return mae_test, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0852c-c8df-467b-8c95-7bf1d43c8062",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e79f06-9964-434d-bfc6-bc7c406f47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NNs with tabular features = 4 (n_citi, bed, bath, sqft)\n",
    "nn_base = base_nn(4)\n",
    "nn_resnet = resnet_nn(4)\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b3b142-72ab-4e70-9961-7d2750d2f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 554ms/step - R2Score: -1.1422 - loss: 405263.1875 - mae: 405263.1875\n",
      "Epoch 2/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 504ms/step - R2Score: 0.0412 - loss: 262758.2500 - mae: 262758.2500\n",
      "Epoch 3/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 534ms/step - R2Score: 0.2272 - loss: 235915.6250 - mae: 235915.6250\n",
      "Epoch 4/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 522ms/step - R2Score: 0.2701 - loss: 228518.2812 - mae: 228518.2812\n",
      "Epoch 5/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 505ms/step - R2Score: 0.3022 - loss: 224010.7656 - mae: 224010.7656\n",
      "Epoch 6/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 540ms/step - R2Score: 0.3215 - loss: 222920.3750 - mae: 222920.3750\n",
      "Epoch 7/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 539ms/step - R2Score: 0.3324 - loss: 220288.2656 - mae: 220288.2656\n",
      "Epoch 8/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 515ms/step - R2Score: 0.3310 - loss: 220313.8750 - mae: 220313.8750\n",
      "Epoch 9/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 506ms/step - R2Score: 0.3301 - loss: 220399.5781 - mae: 220399.5781\n",
      "Epoch 10/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 475ms/step - R2Score: 0.3210 - loss: 220626.3125 - mae: 220626.3125\n",
      "Epoch 11/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 471ms/step - R2Score: 0.3379 - loss: 218683.0312 - mae: 218683.0312\n",
      "Epoch 12/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 478ms/step - R2Score: 0.3388 - loss: 217697.7031 - mae: 217697.7031\n",
      "Epoch 13/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 471ms/step - R2Score: 0.3141 - loss: 219995.3438 - mae: 219995.3438\n",
      "Epoch 14/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 451ms/step - R2Score: 0.3315 - loss: 219996.3594 - mae: 219996.3594\n",
      "Epoch 15/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 457ms/step - R2Score: 0.3385 - loss: 217030.8125 - mae: 217030.8125\n",
      "Epoch 16/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 457ms/step - R2Score: 0.3291 - loss: 219485.1562 - mae: 219485.1562\n",
      "Epoch 17/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 457ms/step - R2Score: 0.3323 - loss: 221366.4375 - mae: 221366.4375\n",
      "Epoch 18/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 466ms/step - R2Score: 0.3326 - loss: 219322.8438 - mae: 219322.8438\n",
      "Epoch 19/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 466ms/step - R2Score: 0.3350 - loss: 216989.3906 - mae: 216989.3906\n",
      "Epoch 20/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 456ms/step - R2Score: 0.3297 - loss: 224478.9844 - mae: 224478.9844\n",
      "Epoch 21/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 455ms/step - R2Score: 0.3422 - loss: 215693.3906 - mae: 215693.3906\n",
      "Epoch 22/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 456ms/step - R2Score: 0.3284 - loss: 218321.6875 - mae: 218321.6875\n",
      "Epoch 23/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 452ms/step - R2Score: 0.3344 - loss: 219892.0625 - mae: 219892.0625\n",
      "Epoch 24/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 456ms/step - R2Score: 0.3342 - loss: 219071.4375 - mae: 219071.4375\n",
      "Epoch 25/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 456ms/step - R2Score: 0.3143 - loss: 220581.1406 - mae: 220581.1406\n",
      "NN Base MAE: 220014\n",
      "NN Base R2: 0.35\n",
      "WARNING:tensorflow:From C:\\Users\\daniel\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "print(\"Training Base NN\")\n",
    "nn_base_hist, _, nn_base_mae, nn_base_r2 = train_and_evaluate_nn(nn_base, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"NN Base MAE: {nn_base_mae:.0f}\\nNN Base R2: {nn_base_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d2d76e-0391-4d59-88c0-32cedb551932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m961s\u001b[0m 1s/step - R2Score: -2.4521 - loss: 563919.8750 - mae: 563919.8750\n",
      "Epoch 2/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 1s/step - R2Score: 0.1991 - loss: 239459.4531 - mae: 239459.4531\n",
      "Epoch 3/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 1s/step - R2Score: 0.3014 - loss: 224556.1562 - mae: 224556.1562\n",
      "Epoch 4/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 1s/step - R2Score: 0.3154 - loss: 219261.7188 - mae: 219261.7188\n",
      "Epoch 5/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m956s\u001b[0m 1s/step - R2Score: 0.3266 - loss: 217687.0781 - mae: 217687.0781\n",
      "Epoch 6/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m964s\u001b[0m 1s/step - R2Score: 0.3433 - loss: 216634.7188 - mae: 216634.7188\n",
      "Epoch 7/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 1s/step - R2Score: 0.3601 - loss: 214348.9688 - mae: 214348.9688\n",
      "Epoch 8/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 1s/step - R2Score: 0.3454 - loss: 211343.7031 - mae: 211343.7031\n",
      "Epoch 9/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 1s/step - R2Score: 0.3714 - loss: 210201.9062 - mae: 210201.9062\n",
      "Epoch 10/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 1s/step - R2Score: 0.3732 - loss: 211751.1719 - mae: 211751.1719\n",
      "Epoch 11/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m957s\u001b[0m 1s/step - R2Score: 0.3711 - loss: 208170.2656 - mae: 208170.2656\n",
      "Epoch 12/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m959s\u001b[0m 1s/step - R2Score: 0.3837 - loss: 209363.8125 - mae: 209363.8125\n",
      "Epoch 13/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m964s\u001b[0m 1s/step - R2Score: 0.3781 - loss: 206785.6406 - mae: 206785.6406\n",
      "Epoch 14/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 1s/step - R2Score: 0.3902 - loss: 210430.2500 - mae: 210430.2500\n",
      "Epoch 15/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 1s/step - R2Score: 0.3813 - loss: 205295.4375 - mae: 205295.4375\n",
      "Epoch 16/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m955s\u001b[0m 1s/step - R2Score: 0.3905 - loss: 207498.1562 - mae: 207498.1562\n",
      "Epoch 17/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m959s\u001b[0m 1s/step - R2Score: 0.3825 - loss: 203427.8594 - mae: 203427.8594\n",
      "Epoch 18/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m967s\u001b[0m 1s/step - R2Score: 0.3905 - loss: 204467.3281 - mae: 204467.3281\n",
      "Epoch 19/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m952s\u001b[0m 1s/step - R2Score: 0.4113 - loss: 202216.9844 - mae: 202216.9844\n",
      "Epoch 20/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m945s\u001b[0m 1s/step - R2Score: 0.4061 - loss: 200007.7188 - mae: 200007.7188\n",
      "Epoch 21/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m948s\u001b[0m 1s/step - R2Score: 0.4037 - loss: 206106.9844 - mae: 206106.9844\n",
      "Epoch 22/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m944s\u001b[0m 1s/step - R2Score: 0.4071 - loss: 203643.1875 - mae: 203643.1875\n",
      "Epoch 23/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 1s/step - R2Score: 0.4108 - loss: 198001.7344 - mae: 198001.7344\n",
      "Epoch 24/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m948s\u001b[0m 1s/step - R2Score: 0.4280 - loss: 194498.7500 - mae: 194498.7500\n",
      "Epoch 25/25\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m949s\u001b[0m 1s/step - R2Score: 0.4353 - loss: 198455.2812 - mae: 198455.2812\n",
      "Resnet MAE: 221416\n",
      "Resnet R2: 0.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet\n",
    "print(\"Training Resnet\")\n",
    "nn_resnet_hist, _, nn_resnet_mae, nn_resnet_r2 = train_and_evaluate_nn(nn_resnet, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"Resnet MAE: {nn_resnet_mae:.0f}\\nResnet R2: {nn_resnet_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f3a6d0-3dbf-4216-8c4b-8fd7348ca5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "LR MAE: 223187\n",
      "LR R2: 0.35\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "print(\"Training LR\")\n",
    "lr_mae, lr_r2 = train_and_evaluate_lin_model(lin, X_train_tab, y_train, X_test_tab, y_test)\n",
    "print(f\"LR MAE: {lr_mae:.0f}\\nLR R2: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c654a-ebdf-4e05-8f86-ad6233d29358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
