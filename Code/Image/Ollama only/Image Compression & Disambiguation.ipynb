{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a29a8-299e-40e1-a74e-1582d18d83fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82983fac-5b01-4856-b440-abbcf7104c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "import ollama\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529c11a4-47d8-4b00-b864-82310156d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CUDA usage\n",
    "os.environ[\"OLLAMA_BACKEND\"] = \"cuda\"\n",
    "os.environ[\"OLLAMA_NUM_THREADS\"] = \"16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1c425-de82-4e64-a2e5-91656221d3bb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c498887a-4781-4cc0-8665-d033c67db850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama visual models\n",
    "llms = ['gemma3:4b', 'llava:7b', 'llava-llama3:8b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4cf5bca-5c72-4f2b-add9-759af2581f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to generate compressions for\n",
    "n_rows = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11db700-611a-4a2d-a854-eae7cba070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Parameters\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8dbadb-684d-49ae-9bf2-6727e0b4e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer for Bag-of-Words\n",
    "bow_max_features = 10000\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=bow_max_features, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdb00-4a1f-4d9b-b80e-226d6ae20a8a",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33258f96-c2f4-46f7-b0dc-3ea2f8527dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work df is randomly sampled df with the size of n_rows which is the number of rows that will be processed by LLMs\n",
    "_, work_df = train_test_split(pd.read_csv(\"houses_preprocessed.csv\"), test_size=n_rows, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc5e38d-6092-4103-8c1b-255e1fac0202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  \n",
       "4772    houses_preprocessed/4793.jpg  \n",
       "3707    houses_preprocessed/3727.jpg  \n",
       "14159  houses_preprocessed/14333.jpg  \n",
       "6934    houses_preprocessed/7055.jpg  \n",
       "13453  houses_preprocessed/13627.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9898847-adf5-4015-b9ab-ec33fc794be1",
   "metadata": {},
   "source": [
    "# LLM Compression Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41effcdc-e265-4157-81e6-c8278bd64e9a",
   "metadata": {},
   "source": [
    "## Method to allign image for Ollama visual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7b7633-b4f3-4a1a-b87d-ad361f3ca60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_image_path_to_base64(image_path):\n",
    "    # Memory management\n",
    "    with Image.open(image_path) as img:\n",
    "        with io.BytesIO() as buffered:\n",
    "            img.save(buffered, format=\"JPEG\")\n",
    "\n",
    "            return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425fd189-18ab-4ec8-a340-7539c146c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory(llm):\n",
    "    # Code to fix memory leak, if above 85% memory usage reload Ollama model\n",
    "    if psutil.virtual_memory().percent > 85:\n",
    "        print(\"Reseting Memory...\")\n",
    "        subprocess.run(['ollama', 'stop', llm])\n",
    "        time.sleep(5)\n",
    "        subprocess.run(['ollama', 'run', llm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ddb94-05d6-4b57-80d1-0c4a45064a3d",
   "metadata": {},
   "source": [
    "## Qualified loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad33f13f-cbdb-4067-a05d-2cef1f8c8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Analyze the given image of the house in great detail, focusing on key features that influence real estate value.\n",
    "Do not attempt to estimate or provide a price! Only describe observable attributes that an appraiser or real estate agent would use to determine value.\n",
    "Provide a neutral, detailed description, without pricing opinions. Provide only objective observations for valuation purposes.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a27e89-fc8c-4a3c-8ee3-1be4c260f988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: gemma3:4b (Model 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  19%|█████████████████████████████████████████▍                                                                                                                                                                                    | 467/2500 [6:26:55<23:27:40, 41.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 874/2500 [11:28:49<20:05:45, 44.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 1282/2500 [16:37:56<14:53:11, 44.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 1689/2500 [21:41:45<10:00:30, 44.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                    | 2090/2500 [26:48:52<5:21:05, 46.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 2433/2500 [31:02:35<1:01:07, 54.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [31:57:07<00:00, 46.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava:7b (Model 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [32:01:05<00:00, 46.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava-llama3:8b (Model 3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 806/2500 [7:56:41<32:51:53, 69.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                      | 807/2500 [7:58:00<34:06:21, 72.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|███████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 808/2500 [7:59:32<36:49:24, 78.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|███████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 809/2500 [8:00:54<37:21:24, 79.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|███████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 810/2500 [8:01:53<34:21:16, 73.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|████████████████████████████████████████████████████████████████████████                                                                                                                                                      | 811/2500 [8:03:12<35:15:06, 75.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  32%|████████████████████████████████████████████████████████████████████████                                                                                                                                                      | 812/2500 [8:04:34<36:09:54, 77.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [33:54:44<00:00, 48.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through models\n",
    "for index, model in enumerate(llms):\n",
    "    print(\"Processing Model: \" + model + \" (Model \" + str(index + 1) + \"/\" + str(len(llms)) + \")\")\n",
    "\n",
    "    # For each row\n",
    "    for index, row in tqdm(work_df.iterrows(), total=len(work_df), desc=\"Parsing rows\"):     \n",
    "        # Memory leak fix\n",
    "        check_memory(model)  \n",
    "        \n",
    "        # Do the necessary image conversion\n",
    "        image = df_image_path_to_base64(row['image'])\n",
    "        \n",
    "        # Regress the price, get rid of commas and periods \n",
    "        response = ollama.generate(model=model, prompt=prompt, images=[image])['response']               \n",
    "       \n",
    "        # Store response\n",
    "        work_df.at[index, f\"{model}_summary\"] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f1d88b-766d-4a89-b107-36dcba728557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "      <th>gemma3:4b_summary</th>\n",
       "      <th>llava:7b_summary</th>\n",
       "      <th>llava-llama3:8b_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "      <td>Okay, here’s a detailed, objective description...</td>\n",
       "      <td>The image shows a single-story residential ho...</td>\n",
       "      <td>The image presents a serene residential scene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "      <td>Okay, here's a detailed, objective description...</td>\n",
       "      <td>The image displays a single-family residentia...</td>\n",
       "      <td>The image presents a single-story house painte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "      <td>Okay, here’s a detailed, objective description...</td>\n",
       "      <td>This image features a two-story residential h...</td>\n",
       "      <td>The image presents a two-story house painted i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "      <td>Okay, here's a detailed, objective description...</td>\n",
       "      <td>The image shows a two-story residential house...</td>\n",
       "      <td>The image captures a serene suburban scene, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "      <td>Here's a detailed, objective description of th...</td>\n",
       "      <td>The image shows a single-story house with sev...</td>\n",
       "      <td>The image captures a quaint scene of a house p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  \\\n",
       "4772    houses_preprocessed/4793.jpg   \n",
       "3707    houses_preprocessed/3727.jpg   \n",
       "14159  houses_preprocessed/14333.jpg   \n",
       "6934    houses_preprocessed/7055.jpg   \n",
       "13453  houses_preprocessed/13627.jpg   \n",
       "\n",
       "                                       gemma3:4b_summary  \\\n",
       "4772   Okay, here’s a detailed, objective description...   \n",
       "3707   Okay, here's a detailed, objective description...   \n",
       "14159  Okay, here’s a detailed, objective description...   \n",
       "6934   Okay, here's a detailed, objective description...   \n",
       "13453  Here's a detailed, objective description of th...   \n",
       "\n",
       "                                        llava:7b_summary  \\\n",
       "4772    The image shows a single-story residential ho...   \n",
       "3707    The image displays a single-family residentia...   \n",
       "14159   This image features a two-story residential h...   \n",
       "6934    The image shows a two-story residential house...   \n",
       "13453   The image shows a single-story house with sev...   \n",
       "\n",
       "                                 llava-llama3:8b_summary  \n",
       "4772   The image presents a serene residential scene ...  \n",
       "3707   The image presents a single-story house painte...  \n",
       "14159  The image presents a two-story house painted i...  \n",
       "6934   The image captures a serene suburban scene, do...  \n",
       "13453  The image captures a quaint scene of a house p...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484a427-3ab5-4a4f-958c-b59e26c5f6cf",
   "metadata": {},
   "source": [
    "# Experimental set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ded195-dc21-4ca2-9bc9-788114c15c7d",
   "metadata": {},
   "source": [
    "## Train and Test the models on the same data partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a19ca1-d3c3-44c8-81ed-f7fbfbc29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df with LLM generated compressions into train and test\n",
    "X_work_df = work_df[work_df.columns.difference(['price'])]\n",
    "y_work_df = work_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_work_df, y_work_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be277f-b973-4df4-a1b6-a1d376ed6b6e",
   "metadata": {},
   "source": [
    "### Compression dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfb3eec-0910-458d-9204-59a153899324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Training Data Shapes:\n",
      "Tabular features: (2000, 7)\n",
      "Image features: (2000,)\n",
      "Target prices: (2000,)\n",
      "\n",
      "Compression Test Data Shapes:\n",
      "Tabular features: (500, 7)\n",
      "Image features: (500,)\n",
      "Target prices: (500,)\n"
     ]
    }
   ],
   "source": [
    "# Train data with compression cols\n",
    "X_train_tab_compression = X_train[X_train.columns.difference(['image'])] # pd\n",
    "X_train_img = X_train['image'] # pd\n",
    "\n",
    "# Test data ith compression cols\n",
    "X_test_tab_compression = X_test[X_test.columns.difference(['image'])] # pd \n",
    "X_test_img = X_test['image'] # pd\n",
    "\n",
    "# Print shapes\n",
    "print(\"Compression Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab_compression.shape}\")\n",
    "print(f\"Image features: {X_train_img.shape}\")\n",
    "print(f\"Target prices: {y_train.shape}\")\n",
    "print(\"\\nCompression Test Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab_compression.shape}\")\n",
    "print(f\"Image features: {X_test_img.shape}\")\n",
    "print(f\"Target prices: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0b041-1d25-4f5b-aab1-30b2aee8bced",
   "metadata": {},
   "source": [
    "### Base dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d2efc17-de13-4dae-88eb-9253b1158896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Tabular features: (2000, 4)\n",
      "\n",
      "Test Data Shapes:\n",
      "Tabular features: (500, 4)\n"
     ]
    }
   ],
   "source": [
    "base_cols = ['n_citi', 'bed', 'bath', 'sqft']\n",
    "\n",
    "# Train and Test data - no compression cols\n",
    "X_train_tab = X_train[base_cols].values \n",
    "X_test_tab = X_test[base_cols].values \n",
    "\n",
    "# Print shapes\n",
    "print(\"Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab.shape}\")\n",
    "print(\"\\nTest Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48ff29-ea29-4c05-bc75-1a88affe93a5",
   "metadata": {},
   "source": [
    "# Neural Networks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4051d7-42e9-4292-911c-71929f87c61f",
   "metadata": {},
   "source": [
    "## Base NN and Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a0b040-e9ae-4980-a338-f186ae2559b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn(input_size_tabular):\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "    \n",
    "    nn_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e67de0c-9641-481d-b8f9-0a495c239ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_nn(input_size_tabular):\n",
    "    # Image processing branch with pre-trained ResNet50\n",
    "    res_net = ResNet50(weights='imagenet', include_top=False, input_shape=(311, 415, 3))\n",
    "    \n",
    "    # Unfreeze only the last 10 layers of resnet (fine-tuning) \n",
    "    res_net.trainable = False \n",
    "    for layer in res_net.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = res_net(img_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "    \n",
    "    # Define the model\n",
    "    res_net_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    res_net_model.compile(optimizer='adam', \n",
    "                          loss='mae',\n",
    "                          metrics=['mae', 'R2Score'])\n",
    "   \n",
    "    # Display model summary debug\n",
    "    # res_net_model.summary()\n",
    "\n",
    "    return res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6986eb4-2d4a-4007-8e5c-5afa5bdd7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, tabular_features, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return (image, tabular_features), label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, tabular_data, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data, labels))\n",
    "    dataset = dataset.map(lambda img, tab, lbl: process_example(img, tab, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(nn, \n",
    "                          X_train_img_paths, X_train_tab, y_train,\n",
    "                          X_test_img_paths, X_test_tab, y_test,\n",
    "                          verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_ds = create_dataset(X_train_img_paths, X_train_tab, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_ds = create_dataset(X_test_img_paths, X_test_tab, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_ds, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1130b83-5ff9-4e2e-ae9e-b3120199c078",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9420a061-071f-42ca-9fa0-6a786483c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lin_model(model, X_train_tab, y_train, X_test_tab, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_tab, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_test_pred = model.predict(X_test_tab)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return mae_test, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e77cd4-cbce-4196-9807-81c9dd7f2de7",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aef68e3-44f8-490e-8b98-d6279dccb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NNs with tabular features = 4 (n_citi, bed, bath, sqft)\n",
    "nn_base = base_nn(4)\n",
    "nn_resnet = resnet_nn(4)\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c9197c-9d4b-4c47-b28b-e8c24dc0cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - R2Score: -3.0475 - loss: 627222.6250 - mae: 627222.6250\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - R2Score: -0.1603 - loss: 268338.7500 - mae: 268338.7500\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - R2Score: -0.1530 - loss: 267106.5938 - mae: 267106.5938\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: -0.1470 - loss: 271209.4688 - mae: 271209.4688\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: -0.1206 - loss: 279016.1250 - mae: 279016.1250\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: -0.0982 - loss: 275680.7812 - mae: 275680.7812\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - R2Score: -0.0657 - loss: 276855.4688 - mae: 276855.4688\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - R2Score: -0.0522 - loss: 261138.1719 - mae: 261138.1719\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: -0.0044 - loss: 259665.2656 - mae: 259665.2656\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.0411 - loss: 253226.8125 - mae: 253226.8125\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.1003 - loss: 248819.3125 - mae: 248819.3125\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.0124 - loss: 243920.9375 - mae: 243920.9375\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.1718 - loss: 241400.6094 - mae: 241400.6094\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.1869 - loss: 236688.1719 - mae: 236688.1719\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.2117 - loss: 228983.1094 - mae: 228983.1094\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.2467 - loss: 234419.5000 - mae: 234419.5000\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.2129 - loss: 229542.0781 - mae: 229542.0781\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.2501 - loss: 225103.9531 - mae: 225103.9531\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.2159 - loss: 225074.2188 - mae: 225074.2188\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - R2Score: 0.2421 - loss: 228283.7188 - mae: 228283.7188\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.2681 - loss: 225578.3750 - mae: 225578.3750\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.2768 - loss: 229646.7969 - mae: 229646.7969\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.2593 - loss: 223945.3906 - mae: 223945.3906\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - R2Score: 0.2932 - loss: 220531.9844 - mae: 220531.9844\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - R2Score: 0.2786 - loss: 227805.0938 - mae: 227805.0938\n",
      "NN Base MAE: 227783\n",
      "NN Base R2: 0.33\n",
      "WARNING:tensorflow:From C:\\Users\\danie\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "print(\"Training Base NN\")\n",
    "nn_base_hist, _, nn_base_mae, nn_base_r2 = train_and_evaluate_nn(nn_base, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"NN Base MAE: {nn_base_mae:.0f}\\nNN Base R2: {nn_base_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c1b0a13-c7dd-4337-a319-c96027193cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - R2Score: -3.8917 - loss: 686153.0625 - mae: 686153.0625\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: -3.3183 - loss: 667710.2500 - mae: 667710.2500\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - R2Score: -1.8100 - loss: 453433.2812 - mae: 453433.2812\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: -0.0618 - loss: 268738.9688 - mae: 268738.9688\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - R2Score: 0.0785 - loss: 248846.0000 - mae: 248846.0000\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - R2Score: 0.0991 - loss: 247852.4375 - mae: 247852.4375\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - R2Score: 0.1297 - loss: 239391.8594 - mae: 239391.8594\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.1365 - loss: 240519.8594 - mae: 240519.8594\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.2100 - loss: 226463.6875 - mae: 226463.6875\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.1989 - loss: 225558.6562 - mae: 225558.6562\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - R2Score: 0.2520 - loss: 227043.2188 - mae: 227043.2188\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.2456 - loss: 217045.6875 - mae: 217045.6875\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3008 - loss: 219268.0469 - mae: 219268.0469\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3279 - loss: 211980.4531 - mae: 211980.4531\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3347 - loss: 203818.0156 - mae: 203818.0156\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3209 - loss: 209315.8906 - mae: 209315.8906\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.3695 - loss: 210189.9688 - mae: 210189.9688\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 3s/step - R2Score: 0.3220 - loss: 203654.9062 - mae: 203654.9062\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.3611 - loss: 202585.4375 - mae: 202585.4375\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3911 - loss: 200024.5625 - mae: 200024.5625\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3840 - loss: 197336.8750 - mae: 197336.8750\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3747 - loss: 208067.8125 - mae: 208067.8125\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - R2Score: 0.3912 - loss: 195237.1406 - mae: 195237.1406\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 3s/step - R2Score: 0.3949 - loss: 195579.3750 - mae: 195579.3750\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - R2Score: 0.3897 - loss: 189520.4844 - mae: 189520.4844\n",
      "Resnet MAE: 228431\n",
      "Resnet R2: 0.34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet\n",
    "print(\"Training Resnet\")\n",
    "nn_resnet_hist, _, nn_resnet_mae, nn_resnet_r2 = train_and_evaluate_nn(nn_resnet, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"Resnet MAE: {nn_resnet_mae:.0f}\\nResnet R2: {nn_resnet_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3677f7b6-ba6c-44f4-bcc3-01fab3160dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "LR MAE: 223539\n",
      "LR R2: 0.39\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "print(\"Training LR\")\n",
    "lr_mae, lr_r2 = train_and_evaluate_lin_model(lin, X_train_tab, y_train, X_test_tab, y_test)\n",
    "print(f\"LR MAE: {lr_mae:.0f}\\nLR R2: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489b451-376a-4116-8312-85079ee58791",
   "metadata": {},
   "source": [
    "# Measure Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4643cea-eb32-46b2-9ac2-99e350029d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gemma3:4b] Average Image Size: 47296 bytes\n",
      "[gemma3:4b] Average Text Size: 1923 bytes\n",
      "[gemma3:4b] Average Compression: 95.93%\n",
      "[gemma3:4b] Average Absolute Compression: 45373 bytes\n",
      "[gemma3:4b] Total Absolute Compression: 113433243 bytes\n",
      "\n",
      "[llava:7b] Average Image Size: 47296 bytes\n",
      "[llava:7b] Average Text Size: 2310 bytes\n",
      "[llava:7b] Average Compression: 95.12%\n",
      "[llava:7b] Average Absolute Compression: 44986 bytes\n",
      "[llava:7b] Total Absolute Compression: 112465902 bytes\n",
      "\n",
      "[llava-llama3:8b] Average Image Size: 47296 bytes\n",
      "[llava-llama3:8b] Average Text Size: 996 bytes\n",
      "[llava-llama3:8b] Average Compression: 97.89%\n",
      "[llava-llama3:8b] Average Absolute Compression: 46300 bytes\n",
      "[llava-llama3:8b] Total Absolute Compression: 115750563 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for llm in llms:\n",
    "    text_col = f\"{llm}_summary\"\n",
    "\n",
    "    image_sizes = []\n",
    "    summary_sizes = []\n",
    "\n",
    "    for idx, row in work_df.iterrows():\n",
    "        image_path = row['image']\n",
    "        summary_text = row[text_col]\n",
    "\n",
    "        image_size = os.path.getsize(image_path)\n",
    "        summary_size = len(summary_text.encode('utf-8'))\n",
    "\n",
    "        image_sizes.append(image_size)\n",
    "        summary_sizes.append(summary_size)\n",
    "\n",
    "    # Totals\n",
    "    total_image_size = sum(image_sizes)\n",
    "    total_summary_size = sum(summary_sizes)\n",
    "    total_abs_compression = total_image_size - total_summary_size\n",
    "\n",
    "    # Averages\n",
    "    avg_image_size = total_image_size / len(image_sizes)\n",
    "    avg_summary_size = total_summary_size / len(summary_sizes)\n",
    "    avg_compression_pct = ((avg_image_size - avg_summary_size) / avg_image_size) * 100\n",
    "    avg_abs_compression = avg_image_size - avg_summary_size\n",
    "\n",
    "    print(f\"[{llm}] Average Image Size: {avg_image_size:.0f} bytes\")\n",
    "    print(f\"[{llm}] Average Text Size: {avg_summary_size:.0f} bytes\")\n",
    "    print(f\"[{llm}] Average Compression: {avg_compression_pct:.2f}%\")\n",
    "    print(f\"[{llm}] Average Absolute Compression: {avg_abs_compression:.0f} bytes\")\n",
    "    print(f\"[{llm}] Total Absolute Compression: {total_abs_compression:.0f} bytes\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8661e7-b679-4347-9046-1c1d266a3faf",
   "metadata": {},
   "source": [
    "# Comparison BOW (Image Summarization) Model vs Default Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf4ee09d-9dee-4925-9bd8-0e7911a9d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(llm, model, X_train_bow, y_train, X_test_bow, y_test):\n",
    "    # Column with the compression text per LLM\n",
    "    text_col = f\"{llm}_summary\"\n",
    "    \n",
    "    # Transform training and test text data\n",
    "    X_train_text = vectorizer.fit_transform(X_train_bow[text_col])\n",
    "    X_test_text = vectorizer.transform(X_test_bow[text_col])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_text, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_test_pred = model.predict(X_test_text)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return test_mae, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "155d61f3-0f25-49f2-88b9-b3d7eff710ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison(llm, model_results):\n",
    "    # DF Structure\n",
    "    comparison_data = {\n",
    "        'Model': [],\n",
    "        'MAE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "    \n",
    "    for model_name, mae, r2 in model_results:\n",
    "        comparison_data['Model'].append(model_name)\n",
    "        comparison_data['MAE'].append(round(mae))\n",
    "        comparison_data['R2'].append(round(r2, 3))\n",
    "    \n",
    "    # Make into df\n",
    "    comparison_df = pd.DataFrame(comparison_data).set_index(\"Model\")\n",
    "    \n",
    "    # Display df\n",
    "    print(f\"Comparison of Models for {llm}\")\n",
    "    display(comparison_df)\n",
    "    print()\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f9792b-ccb1-4a8e-800d-5c92270a8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Models for gemma3:4b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW Logistic Regression</th>\n",
       "      <td>298159</td>\n",
       "      <td>-0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Random Forest</th>\n",
       "      <td>310983</td>\n",
       "      <td>-0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW SVM</th>\n",
       "      <td>282080</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW KNN</th>\n",
       "      <td>386348</td>\n",
       "      <td>-0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Gradient Boosting</th>\n",
       "      <td>314268</td>\n",
       "      <td>-0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular only)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE     R2\n",
       "Model                                 \n",
       "BOW Logistic Regression  298159 -0.129\n",
       "BOW Random Forest        310983 -0.211\n",
       "BOW SVM                  282080  0.015\n",
       "BOW KNN                  386348 -0.801\n",
       "BOW Gradient Boosting    314268 -0.181\n",
       "NN Base                  227783  0.330\n",
       "NN Resnet                228431  0.340\n",
       "LR (tabular only)        223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Models for llava:7b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW Logistic Regression</th>\n",
       "      <td>293683</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Random Forest</th>\n",
       "      <td>319841</td>\n",
       "      <td>-0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW SVM</th>\n",
       "      <td>284108</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW KNN</th>\n",
       "      <td>407877</td>\n",
       "      <td>-0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Gradient Boosting</th>\n",
       "      <td>331829</td>\n",
       "      <td>-0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular only)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE     R2\n",
       "Model                                 \n",
       "BOW Logistic Regression  293683 -0.033\n",
       "BOW Random Forest        319841 -0.239\n",
       "BOW SVM                  284108  0.001\n",
       "BOW KNN                  407877 -0.993\n",
       "BOW Gradient Boosting    331829 -0.343\n",
       "NN Base                  227783  0.330\n",
       "NN Resnet                228431  0.340\n",
       "LR (tabular only)        223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Models for llava-llama3:8b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW Logistic Regression</th>\n",
       "      <td>307549</td>\n",
       "      <td>-0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Random Forest</th>\n",
       "      <td>362486</td>\n",
       "      <td>-0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW SVM</th>\n",
       "      <td>283264</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW KNN</th>\n",
       "      <td>385486</td>\n",
       "      <td>-0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW Gradient Boosting</th>\n",
       "      <td>336167</td>\n",
       "      <td>-0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular only)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE     R2\n",
       "Model                                 \n",
       "BOW Logistic Regression  307549 -0.168\n",
       "BOW Random Forest        362486 -0.577\n",
       "BOW SVM                  283264  0.002\n",
       "BOW KNN                  385486 -0.804\n",
       "BOW Gradient Boosting    336167 -0.439\n",
       "NN Base                  227783  0.330\n",
       "NN Resnet                228431  0.340\n",
       "LR (tabular only)        223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of ml models\n",
    "ml_models = [\n",
    "    ('BOW Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('BOW Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('BOW SVM', SVC(random_state=42)),\n",
    "    ('BOW KNN', KNeighborsClassifier()),\n",
    "    ('BOW Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# For each LLM\n",
    "for llm in llms:\n",
    "    # Save results for each ML model\n",
    "    model_results = []\n",
    "    \n",
    "    # For each ML model\n",
    "    for model_name, model in ml_models:\n",
    "        # Create, train and evaluate bag of words model \n",
    "        mae, r2 = bow(llm, model, X_train_tab_compression, y_train, X_test_tab_compression, y_test)\n",
    "        model_results.append((model_name, mae, r2)) # Save results for each ML model\n",
    "\n",
    "    # Store default results\n",
    "    model_results.append(('NN Base', nn_base_mae, nn_base_r2))\n",
    "    model_results.append(('NN Resnet', nn_resnet_mae, nn_resnet_r2))\n",
    "    model_results.append(('LR (tabular only)', lr_mae, lr_r2))\n",
    "    \n",
    "    # Create and display the comparison per LLM\n",
    "    create_comparison(llm, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b1257-f621-4ab0-8f05-efab7b4bd026",
   "metadata": {},
   "source": [
    "# Comparison NN (tabular, image and text) VS NN (tabular and image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb59fbf3-88f0-47a7-bfe3-31e935d08ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_tab_img_text(input_size_tabular):\n",
    "    # Image data branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Tabular data branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "\n",
    "    # Textual BoW branch\n",
    "    text_input = Input(shape=(bow_max_features,), name='text_input')\n",
    "    t = Dense(256, activation='relu')(text_input)\n",
    "    t = Dense(64, activation='relu')(t)\n",
    "\n",
    "    # Combine all three branches\n",
    "    combined = Concatenate()([x, y, t])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "\n",
    "    # Define the model with all three inputs\n",
    "    nn_model = Model(inputs=[img_input, tabular_input, text_input], outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                     loss='mae',\n",
    "                     metrics=['mae', 'R2Score'])\n",
    "\n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05a321e-6180-4fe6-a0f2-44e2c4f154ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, tabular_features, text_features, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return (image, tabular_features, text_features), label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, tabular_data, text_data, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "    text_data = tf.convert_to_tensor(text_data, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data, text_data, labels))\n",
    "    dataset = dataset.map(lambda img, tab, txt, lbl: process_example(img, tab, txt, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn_tab_img_text(nn, \n",
    "                                       X_train_img_paths, X_train_tab, X_train_text, y_train, \n",
    "                                       X_test_img_paths, X_test_tab, X_test_text, y_test, \n",
    "                                       verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_ds = create_dataset(X_train_img_paths, X_train_tab, X_train_text, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_ds = create_dataset(X_test_img_paths, X_test_tab, X_test_text, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_ds, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01ea150d-9d96-45bf-88cd-c4e840728b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Supress retracing warning\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # '0' = all messages, '3' = fatal only\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71ecdba0-1c70-48c6-9af3-e89e6419280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN (image, tabular, text)\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - R2Score: -2.9077 - loss: 609352.5000 - mae: 609352.5000\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - R2Score: -0.1847 - loss: 283381.6875 - mae: 283381.6875\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 2s/step - R2Score: -0.1098 - loss: 276760.7188 - mae: 276760.7188\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 2s/step - R2Score: -0.0420 - loss: 259812.9062 - mae: 259812.9062\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - R2Score: 0.1323 - loss: 241556.6250 - mae: 241556.6250\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - R2Score: 0.2758 - loss: 208074.6250 - mae: 208074.6250\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - R2Score: 0.3613 - loss: 200927.2812 - mae: 200927.2812\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - R2Score: 0.3919 - loss: 192248.9062 - mae: 192248.9062\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - R2Score: 0.4319 - loss: 180069.6719 - mae: 180069.6719\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - R2Score: 0.4763 - loss: 175073.3594 - mae: 175073.3594\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 1s/step - R2Score: 0.5188 - loss: 163424.5781 - mae: 163424.5781\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - R2Score: 0.5231 - loss: 159216.0156 - mae: 159216.0156\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 1s/step - R2Score: 0.6186 - loss: 136261.2500 - mae: 136261.2500\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 1s/step - R2Score: 0.6290 - loss: 132707.1406 - mae: 132707.1406\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - R2Score: 0.6145 - loss: 133378.4219 - mae: 133378.4219\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 1s/step - R2Score: 0.6371 - loss: 124238.3828 - mae: 124238.3828\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - R2Score: 0.6828 - loss: 114481.0938 - mae: 114481.0938\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - R2Score: 0.6909 - loss: 106117.3906 - mae: 106117.3906\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - R2Score: 0.7406 - loss: 101563.6406 - mae: 101563.6406\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - R2Score: 0.7441 - loss: 94262.5234 - mae: 94262.5234\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - R2Score: 0.7784 - loss: 85230.1797 - mae: 85230.1797\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - R2Score: 0.7846 - loss: 86093.6875 - mae: 86093.6875\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - R2Score: 0.8130 - loss: 71730.8516 - mae: 71730.8516\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - R2Score: 0.8340 - loss: 70719.7109 - mae: 70719.7109\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - R2Score: 0.8255 - loss: 72267.2188 - mae: 72267.2188\n",
      "\n",
      "Comparison of Models for gemma3:4b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN (image, tabular, text)</th>\n",
       "      <td>235452</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base (image, tabular)</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet (image, tabular)</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE     R2\n",
       "Model                                    \n",
       "NN (image, tabular, text)   235452  0.345\n",
       "NN Base (image, tabular)    227783  0.330\n",
       "NN Resnet (image, tabular)  228431  0.340\n",
       "LR (tabular)                223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NN (image, tabular, text)\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - R2Score: -3.2735 - loss: 615984.1250 - mae: 615984.1250\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - R2Score: -0.1619 - loss: 278372.8438 - mae: 278372.8438\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - R2Score: -0.1536 - loss: 285162.0938 - mae: 285162.0938\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - R2Score: -0.1132 - loss: 269768.7812 - mae: 269768.7812\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - R2Score: -0.0320 - loss: 263212.5938 - mae: 263212.5938\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - R2Score: 0.0547 - loss: 252206.0469 - mae: 252206.0469\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - R2Score: 0.1431 - loss: 234349.9844 - mae: 234349.9844\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - R2Score: 0.2396 - loss: 214337.1875 - mae: 214337.1875\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - R2Score: 0.2816 - loss: 203693.5156 - mae: 203693.5156\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - R2Score: 0.3451 - loss: 201658.8750 - mae: 201658.8750\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - R2Score: 0.4080 - loss: 195420.6406 - mae: 195420.6406\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - R2Score: 0.4177 - loss: 179516.5938 - mae: 179516.5938\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - R2Score: 0.4777 - loss: 169852.5156 - mae: 169852.5156\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - R2Score: 0.5197 - loss: 160472.7812 - mae: 160472.7812\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - R2Score: 0.5589 - loss: 147259.3281 - mae: 147259.3281\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - R2Score: 0.5895 - loss: 137610.1250 - mae: 137610.1250\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - R2Score: 0.6417 - loss: 131694.0625 - mae: 131694.0625\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - R2Score: 0.6411 - loss: 119998.2656 - mae: 119998.2656\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 2s/step - R2Score: 0.6782 - loss: 114687.3672 - mae: 114687.3672\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - R2Score: 0.6882 - loss: 110613.9922 - mae: 110613.9922\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - R2Score: 0.7115 - loss: 100920.9219 - mae: 100920.9219\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - R2Score: 0.7431 - loss: 96583.2344 - mae: 96583.2344\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - R2Score: 0.7566 - loss: 90249.4219 - mae: 90249.4219\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - R2Score: 0.7225 - loss: 92058.2891 - mae: 92058.2891\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - R2Score: 0.7880 - loss: 79600.3594 - mae: 79600.3594\n",
      "\n",
      "Comparison of Models for llava:7b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN (image, tabular, text)</th>\n",
       "      <td>247099</td>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base (image, tabular)</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet (image, tabular)</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE     R2\n",
       "Model                                    \n",
       "NN (image, tabular, text)   247099  0.294\n",
       "NN Base (image, tabular)    227783  0.330\n",
       "NN Resnet (image, tabular)  228431  0.340\n",
       "LR (tabular)                223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training NN (image, tabular, text)\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - R2Score: -2.8036 - loss: 615537.3125 - mae: 615537.3125\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - R2Score: -0.1516 - loss: 285395.8125 - mae: 285395.8125\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - R2Score: -0.1553 - loss: 291642.2188 - mae: 291642.2188\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - R2Score: -0.1037 - loss: 281018.2500 - mae: 281018.2500\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - R2Score: -0.0280 - loss: 260381.0156 - mae: 260381.0156\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - R2Score: 0.0865 - loss: 247966.6250 - mae: 247966.6250\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - R2Score: 0.2015 - loss: 223174.7812 - mae: 223174.7812\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - R2Score: 0.2925 - loss: 201565.4062 - mae: 201565.4062\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - R2Score: 0.3955 - loss: 188484.8594 - mae: 188484.8594\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - R2Score: 0.4562 - loss: 172310.5469 - mae: 172310.5469\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - R2Score: 0.4929 - loss: 165828.9688 - mae: 165828.9688\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - R2Score: 0.5431 - loss: 154540.6562 - mae: 154540.6562\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - R2Score: 0.5591 - loss: 148194.2656 - mae: 148194.2656\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - R2Score: 0.6299 - loss: 131204.6094 - mae: 131204.6094\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - R2Score: 0.6673 - loss: 123472.8359 - mae: 123472.8359\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - R2Score: 0.6996 - loss: 108853.2266 - mae: 108853.2266\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - R2Score: 0.7338 - loss: 97105.7344 - mae: 97105.7344\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - R2Score: 0.7312 - loss: 98580.8047 - mae: 98580.8047\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - R2Score: 0.7509 - loss: 94683.0000 - mae: 94683.0000\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - R2Score: 0.8127 - loss: 77146.8906 - mae: 77146.8906\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - R2Score: 0.8187 - loss: 75285.5625 - mae: 75285.5625\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - R2Score: 0.8162 - loss: 73306.9766 - mae: 73306.9766\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - R2Score: 0.8288 - loss: 66003.9531 - mae: 66003.9531\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - R2Score: 0.8443 - loss: 65169.4766 - mae: 65169.4766\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - R2Score: 0.8316 - loss: 64066.2070 - mae: 64066.2070\n",
      "\n",
      "Comparison of Models for llava-llama3:8b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN (image, tabular, text)</th>\n",
       "      <td>249079</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base (image, tabular)</th>\n",
       "      <td>227783</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet (image, tabular)</th>\n",
       "      <td>228431</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR (tabular)</th>\n",
       "      <td>223539</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE     R2\n",
       "Model                                    \n",
       "NN (image, tabular, text)   249079  0.253\n",
       "NN Base (image, tabular)    227783  0.330\n",
       "NN Resnet (image, tabular)  228431  0.340\n",
       "LR (tabular)                223539  0.387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each LLM\n",
    "for llm in llms:\n",
    "    model_results = []\n",
    "    \n",
    "    # NN with image, tabular features (4 base cols) and text (BoW)\n",
    "    nn_tab_img_text_model = nn_tab_img_text(4) # Retracing\n",
    "    \n",
    "    # Column with the compression text per LLM\n",
    "    text_col = f\"{llm}_summary\"\n",
    "    \n",
    "    # Transform training and test text data\n",
    "    X_train_text = vectorizer.fit_transform(X_train[text_col]).toarray()\n",
    "    X_test_text = vectorizer.transform(X_test[text_col]).toarray()\n",
    "\n",
    "    # Create, train and evaluate NN\n",
    "    print(\"Training NN (image, tabular, text)\")\n",
    "    _, _, mae, r2 = train_and_evaluate_nn_tab_img_text(nn_tab_img_text_model, \n",
    "                                                       X_train_img, X_train_tab, X_train_text, y_train,\n",
    "                                                       X_test_img, X_test_tab, X_test_text, y_test)\n",
    "    model_results.append(('NN (image, tabular, text)', mae, r2))\n",
    "\n",
    "    # Store default results\n",
    "    model_results.append(('NN Base (image, tabular)', nn_base_mae, nn_base_r2))\n",
    "    model_results.append(('NN Resnet (image, tabular)', nn_resnet_mae, nn_resnet_r2))\n",
    "    model_results.append(('LR (tabular)', lr_mae, lr_r2))\n",
    "    \n",
    "    # Create and display the comparison per LLM\n",
    "    print()\n",
    "    create_comparison(llm, model_results)\n",
    "    \n",
    "    # Try to clear NN from memory\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
