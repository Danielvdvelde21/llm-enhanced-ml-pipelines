{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a29a8-299e-40e1-a74e-1582d18d83fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82983fac-5b01-4856-b440-abbcf7104c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import ollama\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529c11a4-47d8-4b00-b864-82310156d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CUDA usage\n",
    "os.environ[\"OLLAMA_BACKEND\"] = \"cuda\"\n",
    "os.environ[\"OLLAMA_NUM_THREADS\"] = \"16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1c425-de82-4e64-a2e5-91656221d3bb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c498887a-4781-4cc0-8665-d033c67db850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama visual models\n",
    "llms = ['gemma3:4b', 'llava:7b', 'llava-llama3:8b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c95d444-2954-4441-be76-e12f2ab2f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all letters to stop on LLM should only return integer\n",
    "stop_chars = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cf5bca-5c72-4f2b-add9-759af2581f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to generate features for\n",
    "n_rows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11db700-611a-4a2d-a854-eae7cba070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Parameters\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdb00-4a1f-4d9b-b80e-226d6ae20a8a",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33258f96-c2f4-46f7-b0dc-3ea2f8527dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work df is randomly sampled df with the size of n_rows which is the number of rows that will be processed by LLMs\n",
    "_, work_df = train_test_split(pd.read_csv(\"houses_preprocessed.csv\"), test_size=n_rows, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc5e38d-6092-4103-8c1b-255e1fac0202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  \n",
       "4772    houses_preprocessed/4793.jpg  \n",
       "3707    houses_preprocessed/3727.jpg  \n",
       "14159  houses_preprocessed/14333.jpg  \n",
       "6934    houses_preprocessed/7055.jpg  \n",
       "13453  houses_preprocessed/13627.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9898847-adf5-4015-b9ab-ec33fc794be1",
   "metadata": {},
   "source": [
    "# LLM Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41effcdc-e265-4157-81e6-c8278bd64e9a",
   "metadata": {},
   "source": [
    "## Method to allign image for Ollama visual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7b7633-b4f3-4a1a-b87d-ad361f3ca60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_image_path_to_base64(image_path):\n",
    "    # Memory management\n",
    "    with Image.open(image_path) as img:\n",
    "        with io.BytesIO() as buffered:\n",
    "            img.save(buffered, format=\"JPEG\")\n",
    "\n",
    "            return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e77537f-fdf2-4211-91c5-62a8470fbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory(llm):\n",
    "    # Code to fix memory leak, if above 85% memory usage reload Ollama model\n",
    "    if psutil.virtual_memory().percent > 85:\n",
    "        print(\"Reseting Memory...\")\n",
    "        subprocess.run(['ollama', 'stop', llm])\n",
    "        time.sleep(5)\n",
    "        subprocess.run(['ollama', 'run', llm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ddb94-05d6-4b57-80d1-0c4a45064a3d",
   "metadata": {},
   "source": [
    "## Qualified loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad33f13f-cbdb-4067-a05d-2cef1f8c8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Analyze the image of the house and score it from 1 to 10 strictly based on {metric}. \n",
    "YOU MUST FOLLOW THESE RULES:\n",
    "1. Return ONLY a single integer between 1 and 10, NOTHING ELSE.\n",
    "2. Do not provide explanations, disclaimers, or additional text.\n",
    "3. If the image is unclear try your best anyway to rate it.\n",
    "\n",
    "Your response must be ONLY the number:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df52d8d1-296f-4518-98af-6451af37d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['condition', 'size', 'material', 'uniqueness', 'maintenance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a27e89-fc8c-4a3c-8ee3-1be4c260f988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: gemma3:4b (Model 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:   5%|███▎                                                           | 267/5000 [27:12<7:57:33,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:   9%|█████▊                                                         | 465/5000 [48:45<9:28:08,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  16%|█████████▋                                                  | 810/5000 [3:11:24<10:35:40,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  20%|███████████▉                                                 | 977/5000 [3:31:58<7:52:44,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  25%|██████████████▋                                             | 1227/5000 [3:58:01<6:31:30,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  30%|█████████████████▊                                          | 1483/5000 [4:24:40<6:00:03,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  34%|████████████████████▍                                       | 1703/5000 [4:47:37<5:40:36,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  39%|███████████████████████▍                                    | 1955/5000 [5:13:59<5:14:48,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  44%|██████████████████████████▌                                 | 2210/5000 [5:40:29<4:47:08,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  48%|████████████████████████████▊                               | 2404/5000 [6:00:42<4:31:56,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  53%|███████████████████████████████▊                            | 2648/5000 [6:26:04<4:04:34,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  57%|██████████████████████████████████                          | 2838/5000 [6:45:56<3:45:54,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  62%|████████████████████████████████████▉                       | 3081/5000 [7:11:11<3:19:53,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  65%|███████████████████████████████████████▎                    | 3273/5000 [7:31:11<2:59:32,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  71%|██████████████████████████████████████████▊                 | 3570/5000 [8:03:48<3:26:28,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  76%|█████████████████████████████████████████████▉              | 3825/5000 [8:31:11<3:21:39, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  81%|████████████████████████████████████████████████▉           | 4074/5000 [8:57:19<1:53:59,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  85%|███████████████████████████████████████████████████         | 4259/5000 [9:16:35<1:16:54,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  90%|███████████████████████████████████████████████████████▊      | 4505/5000 [9:42:14<51:56,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  94%|█████████████████████████████████████████████████████████▎   | 4697/5000 [10:02:15<31:00,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows:  99%|████████████████████████████████████████████████████████████▎| 4940/5000 [10:27:30<06:10,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|█████████████████████████████████████████████████████████████| 5000/5000 [10:33:52<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava:7b (Model 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [6:44:47<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava-llama3:8b (Model 3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing rows: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [7:53:22<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through models\n",
    "for index, model in enumerate(llms):\n",
    "    print(\"Processing Model: \" + model + \" (Model \" + str(index + 1) + \"/\" + str(len(llms)) + \")\")\n",
    "\n",
    "    # For each row\n",
    "    for index, row in tqdm(work_df.iterrows(), total=len(work_df), desc=\"Parsing rows\"):     \n",
    "        # Memory leak fix\n",
    "        check_memory(model)\n",
    "    \n",
    "        # For each feature that we will generate \n",
    "        for metric in metrics:\n",
    "\n",
    "            raw_response = None\n",
    "            attempts = 0\n",
    "            success = False\n",
    "\n",
    "            # Try up to 10 times\n",
    "            while attempts < 10 and not success:\n",
    "                try:\n",
    "                    # Format the prompt based on the metric (feature)\n",
    "                    formatted_prompt = prompt.format(metric=metric)\n",
    "                    \n",
    "                    # Do the necessary image conversion\n",
    "                    image = df_image_path_to_base64(row['image'])\n",
    "                    \n",
    "                    # Regress the price\n",
    "                    raw_response = ollama.generate(model=model, \n",
    "                                                   prompt=formatted_prompt, \n",
    "                                                   images=[image], \n",
    "                                                   options={\"stop\": stop_chars})['response']\n",
    "                    response = int(''.join(filter(str.isdigit, raw_response)))\n",
    "                    \n",
    "                    # Assert validity response\n",
    "                    assert 1 <= response <= 10\n",
    "                    \n",
    "                    # Store response\n",
    "                    work_df.at[index, f\"{model}_{metric}\"] = response\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    attempts += 1\n",
    "            \n",
    "            # If all attempts failed, store 5\n",
    "            if not success:\n",
    "                work_df.at[index, f\"{model}_{metric}\"] = 5\n",
    "                print(f\"All attempts failed for model {model}, metric {metric}, row {index}. Storing default value 5.\")\n",
    "                print(raw_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f1d88b-766d-4a89-b107-36dcba728557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "      <th>gemma3:4b_condition</th>\n",
       "      <th>gemma3:4b_size</th>\n",
       "      <th>gemma3:4b_material</th>\n",
       "      <th>gemma3:4b_uniqueness</th>\n",
       "      <th>...</th>\n",
       "      <th>llava:7b_condition</th>\n",
       "      <th>llava:7b_size</th>\n",
       "      <th>llava:7b_material</th>\n",
       "      <th>llava:7b_uniqueness</th>\n",
       "      <th>llava:7b_maintenance</th>\n",
       "      <th>llava-llama3:8b_condition</th>\n",
       "      <th>llava-llama3:8b_size</th>\n",
       "      <th>llava-llama3:8b_material</th>\n",
       "      <th>llava-llama3:8b_uniqueness</th>\n",
       "      <th>llava-llama3:8b_maintenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  gemma3:4b_condition  gemma3:4b_size  \\\n",
       "4772    houses_preprocessed/4793.jpg                  6.0             6.0   \n",
       "3707    houses_preprocessed/3727.jpg                  5.0             4.0   \n",
       "14159  houses_preprocessed/14333.jpg                  6.0             6.0   \n",
       "6934    houses_preprocessed/7055.jpg                  6.0             6.0   \n",
       "13453  houses_preprocessed/13627.jpg                  5.0             4.0   \n",
       "\n",
       "       gemma3:4b_material  gemma3:4b_uniqueness  ...  llava:7b_condition  \\\n",
       "4772                  6.0                   4.0  ...                 6.0   \n",
       "3707                  4.0                   4.0  ...                 5.0   \n",
       "14159                 6.0                   4.0  ...                 8.0   \n",
       "6934                  6.0                   4.0  ...                 7.0   \n",
       "13453                 5.0                   4.0  ...                 5.0   \n",
       "\n",
       "       llava:7b_size  llava:7b_material  llava:7b_uniqueness  \\\n",
       "4772             5.0                4.0                  8.0   \n",
       "3707             8.0                7.0                  5.0   \n",
       "14159            6.0                8.0                  6.0   \n",
       "6934             9.0                8.0                  6.0   \n",
       "13453            5.0                4.0                  1.0   \n",
       "\n",
       "       llava:7b_maintenance  llava-llama3:8b_condition  llava-llama3:8b_size  \\\n",
       "4772                    8.0                        9.0                   1.0   \n",
       "3707                    9.0                        7.0                   8.0   \n",
       "14159                   8.0                        8.0                   7.0   \n",
       "6934                    9.0                        5.0                   1.0   \n",
       "13453                   8.0                        5.0                   7.0   \n",
       "\n",
       "       llava-llama3:8b_material  llava-llama3:8b_uniqueness  \\\n",
       "4772                        5.0                         5.0   \n",
       "3707                        6.0                         4.0   \n",
       "14159                       9.0                         6.0   \n",
       "6934                        9.0                         8.0   \n",
       "13453                       8.0                         8.0   \n",
       "\n",
       "       llava-llama3:8b_maintenance  \n",
       "4772                           7.0  \n",
       "3707                           8.0  \n",
       "14159                          8.0  \n",
       "6934                           9.0  \n",
       "13453                          8.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484a427-3ab5-4a4f-958c-b59e26c5f6cf",
   "metadata": {},
   "source": [
    "# Experimental set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ded195-dc21-4ca2-9bc9-788114c15c7d",
   "metadata": {},
   "source": [
    "## Train and Test the models on the same data partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a19ca1-d3c3-44c8-81ed-f7fbfbc29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df with LLM generated features into train and test\n",
    "X_work_df = work_df[work_df.columns.difference(['price'])]\n",
    "y_work_df = work_df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_work_df, y_work_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be277f-b973-4df4-a1b6-a1d376ed6b6e",
   "metadata": {},
   "source": [
    "### Feature Generation dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfb3eec-0910-458d-9204-59a153899324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG Training Data Shapes:\n",
      "Tabular features: (4000, 19)\n",
      "Image features: (4000,)\n",
      "Target prices: (4000,)\n",
      "\n",
      "FG Test Data Shapes:\n",
      "Tabular features: (1000, 19)\n",
      "Image features: (1000,)\n",
      "Target prices: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Train data feature generation\n",
    "X_train_tab_fg = X_train[X_train.columns.difference(['image'])] # Not yet np array, we will do a further spliting (we need column names)\n",
    "X_train_img = X_train['image'] # pd\n",
    "\n",
    "# Test data feature generation\n",
    "X_test_tab_fg = X_test[X_test.columns.difference(['image'])] # Not yet np array, we will do a further spliting (we need column names) \n",
    "X_test_img = X_test['image'] # pd\n",
    "\n",
    "# Print shapes\n",
    "print(\"FG Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab_fg.shape}\")\n",
    "print(f\"Image features: {X_train_img.shape}\")\n",
    "print(f\"Target prices: {y_train.shape}\")\n",
    "print(\"\\nFG Test Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab_fg.shape}\")\n",
    "print(f\"Image features: {X_test_img.shape}\")\n",
    "print(f\"Target prices: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b80a96-0716-421c-9303-874233a19725",
   "metadata": {},
   "source": [
    "### No Feature Generation dfs\n",
    "1. Train and Test sets of image and y columns are identical\n",
    "2. Reduced tabular features (only base features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e8c5d44-4471-401e-be21-c3aac0b7c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG Training Data Shapes:\n",
      "Tabular features: (4000, 4)\n",
      "\n",
      "FG Test Data Shapes:\n",
      "Tabular features: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "base_cols_no_fg = ['n_citi', 'bed', 'bath', 'sqft']\n",
    "\n",
    "# Train and Test data - no feature generation\n",
    "X_train_tab = X_train[base_cols_no_fg].values \n",
    "X_test_tab = X_test[base_cols_no_fg].values \n",
    "\n",
    "# Print shapes\n",
    "print(\"FG Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab.shape}\")\n",
    "print(\"\\nFG Test Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48ff29-ea29-4c05-bc75-1a88affe93a5",
   "metadata": {},
   "source": [
    "# No Generated Features Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94594a-42c2-4e78-9789-74c1d86aa627",
   "metadata": {},
   "source": [
    "## Neural Networks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4051d7-42e9-4292-911c-71929f87c61f",
   "metadata": {},
   "source": [
    "### Base NN and Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a0b040-e9ae-4980-a338-f186ae2559b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn(input_size_tabular):\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "    \n",
    "    nn_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e67de0c-9641-481d-b8f9-0a495c239ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_nn(input_size_tabular):\n",
    "    # Image processing branch with pre-trained ResNet50\n",
    "    res_net = ResNet50(weights='imagenet', include_top=False, input_shape=(311, 415, 3))\n",
    "    \n",
    "    # Unfreeze only the last 10 layers of resnet (fine-tuning) \n",
    "    res_net.trainable = False \n",
    "    for layer in res_net.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=(311, 415, 3), name='image_input')\n",
    "    x = res_net(img_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Tabular data processing branch\n",
    "    tabular_input = Input(shape=(input_size_tabular,), name='tabular_input')\n",
    "    y = Dense(64, activation='relu')(tabular_input)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    \n",
    "    # Combine both branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    output = Dense(1)(z)  # Regression output for price prediction\n",
    "    \n",
    "    # Define the model\n",
    "    res_net_model = Model(inputs=[img_input, tabular_input], outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    res_net_model.compile(optimizer='adam', \n",
    "                          loss='mae',\n",
    "                          metrics=['mae', 'R2Score'])\n",
    "   \n",
    "    # Display model summary debug\n",
    "    # res_net_model.summary()\n",
    "\n",
    "    return res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6986eb4-2d4a-4007-8e5c-5afa5bdd7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, tabular_features, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return (image, tabular_features), label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, tabular_data, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data, labels))\n",
    "    dataset = dataset.map(lambda img, tab, lbl: process_example(img, tab, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(nn, \n",
    "                          X_train_img_paths, X_train_tab, y_train,\n",
    "                          X_test_img_paths, X_test_tab, y_test,\n",
    "                          verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_ds = create_dataset(X_train_img_paths, X_train_tab, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_ds = create_dataset(X_test_img_paths, X_test_tab, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_ds, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1130b83-5ff9-4e2e-ae9e-b3120199c078",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9420a061-071f-42ca-9fa0-6a786483c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lin_model(model, X_train_tab, y_train, X_test_tab, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_tab, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_test_pred = model.predict(X_test_tab)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return mae_test, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e77cd4-cbce-4196-9807-81c9dd7f2de7",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f7b9e7-cc5f-44e5-8d15-9b55e0548a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NNs with tabular features = 4 (n_citi, bed, bath, sqft)\n",
    "nn_base = base_nn(4)\n",
    "nn_resnet = resnet_nn(4)\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d31893f-f11b-4b9f-8eac-d1d76d626538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 1s/step - R2Score: -2.0636 - loss: 528141.9375 - mae: 528141.9375\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - R2Score: -0.1374 - loss: 289905.4688 - mae: 289905.4688\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 1s/step - R2Score: -0.1071 - loss: 264667.0938 - mae: 264667.0938\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1s/step - R2Score: -0.0529 - loss: 268879.3750 - mae: 268879.3750\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - R2Score: 0.0878 - loss: 245842.0156 - mae: 245842.0156\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 1s/step - R2Score: 0.1823 - loss: 246568.2969 - mae: 246568.2969\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 1s/step - R2Score: 0.2042 - loss: 233154.5469 - mae: 233154.5469\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - R2Score: 0.2470 - loss: 227186.7969 - mae: 227186.7969\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1s/step - R2Score: 0.2227 - loss: 236178.3906 - mae: 236178.3906\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 1s/step - R2Score: 0.2534 - loss: 225520.9062 - mae: 225520.9062\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - R2Score: 0.2281 - loss: 237842.8281 - mae: 237842.8281\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - R2Score: 0.2498 - loss: 224953.1094 - mae: 224953.1094\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 1s/step - R2Score: 0.2860 - loss: 226588.3594 - mae: 226588.3594\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - R2Score: 0.2427 - loss: 224143.9844 - mae: 224143.9844\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1s/step - R2Score: 0.2569 - loss: 219678.5781 - mae: 219678.5781\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - R2Score: 0.2895 - loss: 223313.7031 - mae: 223313.7031\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - R2Score: 0.3046 - loss: 220166.5312 - mae: 220166.5312\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - R2Score: 0.2659 - loss: 229166.1562 - mae: 229166.1562\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - R2Score: 0.3116 - loss: 220881.6250 - mae: 220881.6250\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 1s/step - R2Score: 0.3268 - loss: 218785.3125 - mae: 218785.3125\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 1s/step - R2Score: 0.3342 - loss: 216810.7500 - mae: 216810.7500\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 1s/step - R2Score: 0.3157 - loss: 221703.2344 - mae: 221703.2344\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 1s/step - R2Score: 0.3213 - loss: 221211.5156 - mae: 221211.5156\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - R2Score: 0.3215 - loss: 213012.4062 - mae: 213012.4062\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - R2Score: 0.3425 - loss: 215672.4062 - mae: 215672.4062\n",
      "NN Base MAE: 225426\n",
      "NN Base R2: 0.34\n",
      "WARNING:tensorflow:From C:\\Users\\danie\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "print(\"Training Base NN\")\n",
    "nn_base_hist, _, nn_base_mae, nn_base_r2 = train_and_evaluate_nn(nn_base, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"NN Base MAE: {nn_base_mae:.0f}\\nNN Base R2: {nn_base_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8847d730-e1e5-49f3-919b-488a365b4eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 3s/step - R2Score: -3.4295 - loss: 698511.6250 - mae: 698511.6250\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 3s/step - R2Score: -0.7888 - loss: 360914.3750 - mae: 360914.3750\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 3s/step - R2Score: 0.0782 - loss: 249789.4375 - mae: 249789.4375\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - R2Score: 0.1251 - loss: 250966.8750 - mae: 250966.8750\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3s/step - R2Score: 0.2241 - loss: 235338.7969 - mae: 235338.7969\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 3s/step - R2Score: 0.2663 - loss: 224944.4062 - mae: 224944.4062\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - R2Score: 0.2938 - loss: 221056.2188 - mae: 221056.2188\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 3s/step - R2Score: 0.3298 - loss: 223511.9375 - mae: 223511.9375\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 3s/step - R2Score: 0.3229 - loss: 217706.3125 - mae: 217706.3125\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3112 - loss: 226227.3906 - mae: 226227.3906\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 2s/step - R2Score: 0.3021 - loss: 213722.0938 - mae: 213722.0938\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3336 - loss: 219487.6406 - mae: 219487.6406\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 2s/step - R2Score: 0.3314 - loss: 211767.6875 - mae: 211767.6875\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3927 - loss: 204969.4219 - mae: 204969.4219\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - R2Score: 0.3899 - loss: 209349.6250 - mae: 209349.6250\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 3s/step - R2Score: 0.3509 - loss: 207498.5156 - mae: 207498.5156\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3778 - loss: 201221.1406 - mae: 201221.1406\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 2s/step - R2Score: 0.3770 - loss: 206902.1250 - mae: 206902.1250\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3857 - loss: 202773.4844 - mae: 202773.4844\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 3s/step - R2Score: 0.3635 - loss: 200028.8750 - mae: 200028.8750\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 3s/step - R2Score: 0.3952 - loss: 198921.4219 - mae: 198921.4219\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 2s/step - R2Score: 0.4248 - loss: 202249.4844 - mae: 202249.4844\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 3s/step - R2Score: 0.4095 - loss: 202746.6250 - mae: 202746.6250\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 3s/step - R2Score: 0.4180 - loss: 191693.3594 - mae: 191693.3594\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 3s/step - R2Score: 0.4229 - loss: 202275.5938 - mae: 202275.5938\n",
      "Resnet MAE: 394746\n",
      "Resnet R2: -0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet\n",
    "print(\"Training Resnet\")\n",
    "nn_resnet_hist, _, nn_resnet_mae, nn_resnet_r2 = train_and_evaluate_nn(nn_resnet, X_train_img, X_train_tab, y_train, X_test_img, X_test_tab, y_test)\n",
    "print(f\"Resnet MAE: {nn_resnet_mae:.0f}\\nResnet R2: {nn_resnet_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac8b03c5-8b35-48f8-b5d4-8fedd12c02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "LR MAE: 227976\n",
      "LR R2: 0.35\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "print(\"Training LR\")\n",
    "lr_mae, lr_r2 = train_and_evaluate_lin_model(lin, X_train_tab, y_train, X_test_tab, y_test)\n",
    "print(f\"LR MAE: {lr_mae:.0f}\\nLR R2: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8661e7-b679-4347-9046-1c1d266a3faf",
   "metadata": {},
   "source": [
    "# Generated Features Neural Networks\n",
    "1. We have to split the LLM generated data into train and test. Such that we can experiment the performance difference.\n",
    "2. We have to create a new architecture for the NN, which are exactly the same except now the input sizes are different, because we have more tabular features generated by the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cb1c9-dc19-416b-a566-d1f9837aa5b4",
   "metadata": {},
   "source": [
    "## Comparison Feature Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "155d61f3-0f25-49f2-88b9-b3d7eff710ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison(llm, \n",
    "                      nn_base_mae_fg, nn_resnet_mae_fg, lr_mae_fg, nn_base_mae, nn_resnet_mae, lr_mae,\n",
    "                      nn_base_r2_fg, nn_resnet_r2_fg, lr_r2_fg, nn_base_r2, nn_resnet_r2, lr_r2\n",
    "                     ):\n",
    "    \n",
    "    # Create a dictionary with the model names and their performance metrics\n",
    "    comparison = {\n",
    "        'Model': ['FG: NN_base ' + llm, 'FG: NN_ResNet ' + llm, 'FG: LR ' + llm, 'NN_base', 'NN_ResNet', 'LR'],\n",
    "        'MAE': [\n",
    "            round(nn_base_mae_fg),\n",
    "            round(nn_resnet_mae_fg),\n",
    "            round(lr_mae_fg),\n",
    "            round(nn_base_mae),\n",
    "            round(nn_resnet_mae),\n",
    "            round(lr_mae)\n",
    "        ],\n",
    "        'R2': [\n",
    "            round(nn_base_r2_fg, 3),\n",
    "            round(nn_resnet_r2_fg, 3),\n",
    "            round(lr_r2_fg, 3),\n",
    "            round(nn_base_r2, 3),\n",
    "            round(nn_resnet_r2, 3),\n",
    "            round(lr_r2, 3)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Make into df\n",
    "    comparison_df = pd.DataFrame(comparison).set_index(\"Model\")\n",
    "\n",
    "    # Display df\n",
    "    print(f\"\\nComparison FG vs no FG for {llm}\")\n",
    "    display(comparison_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e1153e-20df-48a9-9b16-04905480194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Supress retracing warning\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # '0' = all messages, '3' = fatal only\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f9792b-ccb1-4a8e-800d-5c92270a8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 1s/step - R2Score: -2.3443 - loss: 532745.3750 - mae: 532745.3750\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - R2Score: -0.1493 - loss: 269796.4062 - mae: 269796.4062\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 2s/step - R2Score: -0.1351 - loss: 279305.0312 - mae: 279305.0312\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - R2Score: -0.0981 - loss: 277794.6562 - mae: 277794.6562\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - R2Score: -0.0474 - loss: 269216.5938 - mae: 269216.5938\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - R2Score: 0.0626 - loss: 243594.1875 - mae: 243594.1875\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 1s/step - R2Score: 0.1411 - loss: 243646.7500 - mae: 243646.7500\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - R2Score: 0.2106 - loss: 233578.5781 - mae: 233578.5781\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 1s/step - R2Score: 0.2449 - loss: 235738.2656 - mae: 235738.2656\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 1s/step - R2Score: 0.2403 - loss: 228293.9219 - mae: 228293.9219\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 1s/step - R2Score: 0.2971 - loss: 225259.5469 - mae: 225259.5469\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 1s/step - R2Score: 0.2769 - loss: 222834.3750 - mae: 222834.3750\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - R2Score: 0.2984 - loss: 219014.7031 - mae: 219014.7031\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 1s/step - R2Score: 0.2866 - loss: 218476.3438 - mae: 218476.3438\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 1s/step - R2Score: 0.2489 - loss: 219061.2812 - mae: 219061.2812\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 1s/step - R2Score: 0.2413 - loss: 221865.7188 - mae: 221865.7188\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - R2Score: 0.2729 - loss: 220011.4219 - mae: 220011.4219\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 1s/step - R2Score: 0.2752 - loss: 222810.3594 - mae: 222810.3594\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - R2Score: 0.2688 - loss: 219574.7812 - mae: 219574.7812\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - R2Score: 0.2636 - loss: 224591.7500 - mae: 224591.7500\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 1s/step - R2Score: 0.3003 - loss: 220186.4062 - mae: 220186.4062\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 1s/step - R2Score: 0.2881 - loss: 221136.8125 - mae: 221136.8125\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 1s/step - R2Score: 0.3073 - loss: 223782.7812 - mae: 223782.7812\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - R2Score: 0.3167 - loss: 218318.8906 - mae: 218318.8906\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 1s/step - R2Score: 0.3165 - loss: 213383.8125 - mae: 213383.8125\n",
      "\n",
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 3s/step - R2Score: -3.3549 - loss: 687357.3125 - mae: 687357.3125\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: -0.6731 - loss: 339965.5312 - mae: 339965.5312\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: 0.0605 - loss: 254706.2969 - mae: 254706.2969\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 3s/step - R2Score: 0.1117 - loss: 244250.1094 - mae: 244250.1094\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 3s/step - R2Score: 0.1481 - loss: 243141.3750 - mae: 243141.3750\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: 0.1734 - loss: 236241.1250 - mae: 236241.1250\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: 0.2089 - loss: 224619.9062 - mae: 224619.9062\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 3s/step - R2Score: 0.2377 - loss: 229715.4062 - mae: 229715.4062\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - R2Score: 0.2773 - loss: 223619.3906 - mae: 223619.3906\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 3s/step - R2Score: 0.2972 - loss: 219523.4688 - mae: 219523.4688\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 3s/step - R2Score: 0.2766 - loss: 218243.3906 - mae: 218243.3906\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 3s/step - R2Score: 0.3236 - loss: 210221.8438 - mae: 210221.8438\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: 0.3274 - loss: 207845.7344 - mae: 207845.7344\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 3s/step - R2Score: 0.3426 - loss: 212901.3750 - mae: 212901.3750\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 3s/step - R2Score: 0.3322 - loss: 208688.5938 - mae: 208688.5938\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 3s/step - R2Score: 0.3290 - loss: 218310.3906 - mae: 218310.3906\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 3s/step - R2Score: 0.3429 - loss: 207265.4688 - mae: 207265.4688\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 3s/step - R2Score: 0.3355 - loss: 206596.5781 - mae: 206596.5781\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 3s/step - R2Score: 0.3654 - loss: 205948.8594 - mae: 205948.8594\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 3s/step - R2Score: 0.3579 - loss: 207940.2500 - mae: 207940.2500\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 3s/step - R2Score: 0.3928 - loss: 206442.2188 - mae: 206442.2188\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 3s/step - R2Score: 0.3748 - loss: 204371.6562 - mae: 204371.6562\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 3s/step - R2Score: 0.3903 - loss: 203280.1875 - mae: 203280.1875\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 3s/step - R2Score: 0.3738 - loss: 202307.2031 - mae: 202307.2031\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 3s/step - R2Score: 0.3995 - loss: 196388.7031 - mae: 196388.7031\n",
      "\n",
      "Comparison FG vs no FG for gemma3:4b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FG: NN_base gemma3:4b</th>\n",
       "      <td>227921</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: NN_ResNet gemma3:4b</th>\n",
       "      <td>222521</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: LR gemma3:4b</th>\n",
       "      <td>223438</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_base</th>\n",
       "      <td>225426</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_ResNet</th>\n",
       "      <td>394746</td>\n",
       "      <td>-0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>227976</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE     R2\n",
       "Model                                 \n",
       "FG: NN_base gemma3:4b    227921  0.336\n",
       "FG: NN_ResNet gemma3:4b  222521  0.339\n",
       "FG: LR gemma3:4b         223438  0.380\n",
       "NN_base                  225426  0.341\n",
       "NN_ResNet                394746 -0.681\n",
       "LR                       227976  0.354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - R2Score: -2.2125 - loss: 526232.2500 - mae: 526232.2500\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - R2Score: -0.1410 - loss: 279496.0000 - mae: 279496.0000\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - R2Score: -0.1403 - loss: 281180.5000 - mae: 281180.5000\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - R2Score: -0.1210 - loss: 283355.2500 - mae: 283355.2500\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 1s/step - R2Score: -0.0308 - loss: 264731.3125 - mae: 264731.3125\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - R2Score: 0.0555 - loss: 258191.6406 - mae: 258191.6406\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 1s/step - R2Score: 0.1444 - loss: 236524.8438 - mae: 236524.8438\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - R2Score: 0.2150 - loss: 230680.9531 - mae: 230680.9531\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 2s/step - R2Score: 0.2280 - loss: 235742.4219 - mae: 235742.4219\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 2s/step - R2Score: 0.2602 - loss: 222992.5625 - mae: 222992.5625\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 1s/step - R2Score: 0.2582 - loss: 225422.2031 - mae: 225422.2031\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 1s/step - R2Score: 0.2862 - loss: 227660.7500 - mae: 227660.7500\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 1s/step - R2Score: 0.2701 - loss: 226695.9062 - mae: 226695.9062\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - R2Score: 0.2563 - loss: 230287.1406 - mae: 230287.1406\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - R2Score: 0.2471 - loss: 225979.7031 - mae: 225979.7031\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 1s/step - R2Score: 0.2640 - loss: 227630.2969 - mae: 227630.2969\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 1s/step - R2Score: 0.2726 - loss: 221958.7500 - mae: 221958.7500\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 1s/step - R2Score: 0.2593 - loss: 220883.3750 - mae: 220883.3750\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 1s/step - R2Score: 0.2814 - loss: 232146.0625 - mae: 232146.0625\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 1s/step - R2Score: 0.2912 - loss: 226690.2500 - mae: 226690.2500\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 1s/step - R2Score: 0.2713 - loss: 224660.6719 - mae: 224660.6719\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1s/step - R2Score: 0.2575 - loss: 226398.4688 - mae: 226398.4688\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - R2Score: 0.2794 - loss: 224222.0938 - mae: 224222.0938\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - R2Score: 0.2914 - loss: 222594.7500 - mae: 222594.7500\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - R2Score: 0.2787 - loss: 225284.8125 - mae: 225284.8125\n",
      "\n",
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 3s/step - R2Score: -3.4760 - loss: 698407.3750 - mae: 698407.3750\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 3s/step - R2Score: -1.2480 - loss: 419051.5000 - mae: 419051.5000\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - R2Score: 0.0815 - loss: 246321.7969 - mae: 246321.7969\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 3s/step - R2Score: 0.1270 - loss: 243327.2344 - mae: 243327.2344\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 3s/step - R2Score: 0.1543 - loss: 242769.9219 - mae: 242769.9219\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 3s/step - R2Score: 0.1820 - loss: 237189.7344 - mae: 237189.7344\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 3s/step - R2Score: 0.2016 - loss: 230986.8125 - mae: 230986.8125\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - R2Score: 0.2196 - loss: 229604.1406 - mae: 229604.1406\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 3s/step - R2Score: 0.2456 - loss: 228153.3125 - mae: 228153.3125\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 3s/step - R2Score: 0.2509 - loss: 228858.8594 - mae: 228858.8594\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 3s/step - R2Score: 0.2639 - loss: 220518.1094 - mae: 220518.1094\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - R2Score: 0.2834 - loss: 216487.5781 - mae: 216487.5781\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - R2Score: 0.3063 - loss: 213174.4062 - mae: 213174.4062\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3563 - loss: 209135.1875 - mae: 209135.1875\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3044 - loss: 209767.0625 - mae: 209767.0625\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3340 - loss: 209049.8594 - mae: 209049.8594\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - R2Score: 0.3317 - loss: 211838.4844 - mae: 211838.4844\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3402 - loss: 209356.4531 - mae: 209356.4531\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3371 - loss: 207246.9062 - mae: 207246.9062\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - R2Score: 0.3660 - loss: 207375.0312 - mae: 207375.0312\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - R2Score: 0.3370 - loss: 206088.9844 - mae: 206088.9844\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - R2Score: 0.3593 - loss: 202587.6250 - mae: 202587.6250\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3547 - loss: 206960.8438 - mae: 206960.8438\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - R2Score: 0.4040 - loss: 201144.6562 - mae: 201144.6562\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - R2Score: 0.3427 - loss: 203603.9062 - mae: 203603.9062\n",
      "\n",
      "Comparison FG vs no FG for llava:7b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FG: NN_base llava:7b</th>\n",
       "      <td>228054</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: NN_ResNet llava:7b</th>\n",
       "      <td>291150</td>\n",
       "      <td>-0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: LR llava:7b</th>\n",
       "      <td>225858</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_base</th>\n",
       "      <td>225426</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_ResNet</th>\n",
       "      <td>394746</td>\n",
       "      <td>-0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>227976</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MAE     R2\n",
       "Model                                \n",
       "FG: NN_base llava:7b    228054  0.311\n",
       "FG: NN_ResNet llava:7b  291150 -0.141\n",
       "FG: LR llava:7b         225858  0.364\n",
       "NN_base                 225426  0.341\n",
       "NN_ResNet               394746 -0.681\n",
       "LR                      227976  0.354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - R2Score: -2.1219 - loss: 529647.7500 - mae: 529647.7500\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: -0.1499 - loss: 286559.9375 - mae: 286559.9375\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: -0.1337 - loss: 279824.0000 - mae: 279824.0000\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: -0.0990 - loss: 273704.5625 - mae: 273704.5625\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 1s/step - R2Score: -0.0557 - loss: 267502.6562 - mae: 267502.6562\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: 0.0473 - loss: 253997.0625 - mae: 253997.0625\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.1342 - loss: 240418.5625 - mae: 240418.5625\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.1971 - loss: 231067.0156 - mae: 231067.0156\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - R2Score: 0.2129 - loss: 233174.2188 - mae: 233174.2188\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.2266 - loss: 231751.5938 - mae: 231751.5938\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - R2Score: 0.2312 - loss: 226022.2656 - mae: 226022.2656\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 1s/step - R2Score: 0.2700 - loss: 227723.2656 - mae: 227723.2656\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: 0.2401 - loss: 231111.5938 - mae: 231111.5938\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - R2Score: 0.2427 - loss: 229708.7812 - mae: 229708.7812\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.2545 - loss: 223556.6562 - mae: 223556.6562\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - R2Score: 0.2569 - loss: 219814.2344 - mae: 219814.2344\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.2365 - loss: 233600.8438 - mae: 233600.8438\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - R2Score: 0.2604 - loss: 225694.5312 - mae: 225694.5312\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: 0.2680 - loss: 225544.5000 - mae: 225544.5000\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - R2Score: 0.3138 - loss: 222442.0781 - mae: 222442.0781\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - R2Score: 0.2862 - loss: 226474.2344 - mae: 226474.2344\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - R2Score: 0.2689 - loss: 225778.3438 - mae: 225778.3438\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - R2Score: 0.2845 - loss: 224545.5000 - mae: 224545.5000\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.3093 - loss: 225789.9688 - mae: 225789.9688\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - R2Score: 0.2725 - loss: 223923.0469 - mae: 223923.0469\n",
      "\n",
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 2s/step - R2Score: -3.5721 - loss: 672025.7500 - mae: 672025.7500\n",
      "Epoch 2/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 3s/step - R2Score: -0.4774 - loss: 314159.4375 - mae: 314159.4375\n",
      "Epoch 3/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 3s/step - R2Score: 0.0530 - loss: 248296.5469 - mae: 248296.5469\n",
      "Epoch 4/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 3s/step - R2Score: 0.0900 - loss: 245590.7188 - mae: 245590.7188\n",
      "Epoch 5/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 3s/step - R2Score: 0.1183 - loss: 248729.2188 - mae: 248729.2188\n",
      "Epoch 6/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 3s/step - R2Score: 0.1713 - loss: 236875.7031 - mae: 236875.7031\n",
      "Epoch 7/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 3s/step - R2Score: 0.1790 - loss: 234069.2812 - mae: 234069.2812\n",
      "Epoch 8/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 3s/step - R2Score: 0.1899 - loss: 234270.9062 - mae: 234270.9062\n",
      "Epoch 9/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 3s/step - R2Score: 0.2399 - loss: 224069.1094 - mae: 224069.1094\n",
      "Epoch 10/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 3s/step - R2Score: 0.2457 - loss: 224231.9375 - mae: 224231.9375\n",
      "Epoch 11/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 3s/step - R2Score: 0.2911 - loss: 218763.5625 - mae: 218763.5625\n",
      "Epoch 12/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 3s/step - R2Score: 0.2807 - loss: 217889.0000 - mae: 217889.0000\n",
      "Epoch 13/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 3s/step - R2Score: 0.3164 - loss: 215121.7188 - mae: 215121.7188\n",
      "Epoch 14/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 3s/step - R2Score: 0.3049 - loss: 215988.8594 - mae: 215988.8594\n",
      "Epoch 15/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 3s/step - R2Score: 0.3291 - loss: 214149.1250 - mae: 214149.1250\n",
      "Epoch 16/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - R2Score: 0.2943 - loss: 218757.0156 - mae: 218757.0156\n",
      "Epoch 17/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 3s/step - R2Score: 0.3374 - loss: 211760.6719 - mae: 211760.6719\n",
      "Epoch 18/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 3s/step - R2Score: 0.3224 - loss: 211061.5938 - mae: 211061.5938\n",
      "Epoch 19/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 3s/step - R2Score: 0.3777 - loss: 202377.4688 - mae: 202377.4688\n",
      "Epoch 20/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 3s/step - R2Score: 0.3527 - loss: 210406.9688 - mae: 210406.9688\n",
      "Epoch 21/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - R2Score: 0.3587 - loss: 206398.2188 - mae: 206398.2188\n",
      "Epoch 22/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 3s/step - R2Score: 0.3671 - loss: 201603.8125 - mae: 201603.8125\n",
      "Epoch 23/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 3s/step - R2Score: 0.3857 - loss: 200101.4219 - mae: 200101.4219\n",
      "Epoch 24/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 3s/step - R2Score: 0.3289 - loss: 204892.2969 - mae: 204892.2969\n",
      "Epoch 25/25\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 3s/step - R2Score: 0.3858 - loss: 207088.4062 - mae: 207088.4062\n",
      "\n",
      "Comparison FG vs no FG for llava-llama3:8b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FG: NN_base llava-llama3:8b</th>\n",
       "      <td>230746</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: NN_ResNet llava-llama3:8b</th>\n",
       "      <td>245459</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG: LR llava-llama3:8b</th>\n",
       "      <td>228976</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_base</th>\n",
       "      <td>225426</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_ResNet</th>\n",
       "      <td>394746</td>\n",
       "      <td>-0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>227976</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MAE     R2\n",
       "Model                                       \n",
       "FG: NN_base llava-llama3:8b    230746  0.325\n",
       "FG: NN_ResNet llava-llama3:8b  245459  0.319\n",
       "FG: LR llava-llama3:8b         228976  0.350\n",
       "NN_base                        225426  0.341\n",
       "NN_ResNet                      394746 -0.681\n",
       "LR                             227976  0.354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each LLM\n",
    "for llm in llms:\n",
    "    # Should be 9 features --> 5 metrics cols plus 4 base cols\n",
    "    nn_base_fg = base_nn(9)\n",
    "    nn_resnet_fg = resnet_nn(9)\n",
    "    lin_fg = LinearRegression()\n",
    "\n",
    "    # Generated features by LLM\n",
    "    fg_cols = [f\"{llm}_{metric}\" for metric in metrics]\n",
    "    \n",
    "    # Per LLM selected columns (base and LLM generated metrics)\n",
    "    base_plus_fg_cols = ['n_citi', 'bed', 'bath', 'sqft'] + fg_cols\n",
    "\n",
    "    # NN\n",
    "    print(\"Training Base NN\")\n",
    "    _, _, nn_base_mae_fg, nn_base_r2_fg = train_and_evaluate_nn(nn_base_fg, \n",
    "                                                                     X_train_img, X_train_tab_fg[base_plus_fg_cols].values, y_train, \n",
    "                                                                     X_test_img, X_test_tab_fg[base_plus_fg_cols].values, y_test)\n",
    "    \n",
    "    # Resnet\n",
    "    print(\"\\nTraining Resnet\")\n",
    "    _, _, nn_resnet_mae_fg, nn_resnet_r2_fg = train_and_evaluate_nn(nn_resnet_fg, \n",
    "                                                                           X_train_img, X_train_tab_fg[base_plus_fg_cols].values, y_train, \n",
    "                                                                           X_test_img, X_test_tab_fg[base_plus_fg_cols].values, y_test)\n",
    "    \n",
    "    # LR\n",
    "    lr_mae_fg, lr_r2_fg = train_and_evaluate_lin_model(lin_fg, \n",
    "                                                       X_train_tab_fg[base_plus_fg_cols].values, y_train,\n",
    "                                                       X_test_tab_fg[base_plus_fg_cols].values, y_test)\n",
    "\n",
    "    # Create and display the comparison per LLM\n",
    "    create_comparison(llm, \n",
    "                      nn_base_mae_fg, nn_resnet_mae_fg, lr_mae_fg, nn_base_mae, nn_resnet_mae, lr_mae,\n",
    "                      nn_base_r2_fg, nn_resnet_r2_fg, lr_r2_fg, nn_base_r2, nn_resnet_r2, lr_r2)\n",
    "\n",
    "    # Try to clear NN from memory\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
