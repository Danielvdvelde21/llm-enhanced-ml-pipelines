{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a29a8-299e-40e1-a74e-1582d18d83fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82983fac-5b01-4856-b440-abbcf7104c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "import ollama\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529c11a4-47d8-4b00-b864-82310156d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CUDA usage\n",
    "os.environ[\"OLLAMA_BACKEND\"] = \"cuda\"\n",
    "os.environ[\"OLLAMA_NUM_THREADS\"] = \"16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1c425-de82-4e64-a2e5-91656221d3bb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c498887a-4781-4cc0-8665-d033c67db850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama visual models\n",
    "llms = ['gemma3:4b', 'llava:7b', 'llava-llama3:8b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525e0dec-56d5-42a1-8168-b4f25c3a58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all letters to stop on LLM should only return integer\n",
    "stop_chars = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cf5bca-5c72-4f2b-add9-759af2581f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows to generate features for\n",
    "n_rows = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11db700-611a-4a2d-a854-eae7cba070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Parameters\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdb00-4a1f-4d9b-b80e-226d6ae20a8a",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33258f96-c2f4-46f7-b0dc-3ea2f8527dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test set as the same size as the number of rows we process with LLM\n",
    "df_train, df_test = train_test_split(pd.read_csv(\"houses_preprocessed.csv\"), test_size=n_rows, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc5e38d-6092-4103-8c1b-255e1fac0202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  \n",
       "4772    houses_preprocessed/4793.jpg  \n",
       "3707    houses_preprocessed/3727.jpg  \n",
       "14159  houses_preprocessed/14333.jpg  \n",
       "6934    houses_preprocessed/7055.jpg  \n",
       "13453  houses_preprocessed/13627.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9898847-adf5-4015-b9ab-ec33fc794be1",
   "metadata": {},
   "source": [
    "# LLM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41effcdc-e265-4157-81e6-c8278bd64e9a",
   "metadata": {},
   "source": [
    "## Method to allign image for Ollama visual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7b7633-b4f3-4a1a-b87d-ad361f3ca60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_image_path_to_base64(image_path):\n",
    "    # Memory management\n",
    "    with Image.open(image_path) as img:\n",
    "        with io.BytesIO() as buffered:\n",
    "            img.save(buffered, format=\"JPEG\")\n",
    "\n",
    "            return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5997914-0531-445d-a23f-520375d3ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory(llm):\n",
    "    # Code to fix memory leak, if above 85% memory usage reload Ollama model\n",
    "    if psutil.virtual_memory().percent > 85:\n",
    "        print(\"Reseting Memory...\")\n",
    "        subprocess.run(['ollama', 'stop', llm])\n",
    "        time.sleep(5)\n",
    "        subprocess.run(['ollama', 'run', llm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ddb94-05d6-4b57-80d1-0c4a45064a3d",
   "metadata": {},
   "source": [
    "## Qualified loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad33f13f-cbdb-4067-a05d-2cef1f8c8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''you MUST Estimate the full dollar value of this house based solely on the image.\n",
    "\n",
    "RULES:\n",
    "1. Respond with the FULL NUMBER in digits only (e.g., write 500000 instead of 500 or 500k).\n",
    "2. Do NOT use any symbols, text, letters, commas, or punctuation.\n",
    "3. Do NOT explain or justify your answer.\n",
    "4. If the image is unclear, make your best estimate.\n",
    "\n",
    "Your response MUST be a full number like 450000 or 375000:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a27e89-fc8c-4a3c-8ee3-1be4c260f988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: gemma3:4b (Model 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  10%|██████████████████████▋                                                                                                                                                                                                       | 512/5000 [38:47<5:38:54,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  21%|█████████████████████████████████████████████▉                                                                                                                                                                             | 1049/5000 [1:18:57<4:52:42,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  32%|█████████████████████████████████████████████████████████████████████▎                                                                                                                                                     | 1582/5000 [1:58:42<4:14:08,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  42%|████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2111/5000 [2:38:25<3:34:36,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2649/5000 [3:18:54<2:55:21,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3198/5000 [3:59:50<2:13:46,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3739/5000 [4:40:11<1:33:25,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4275/5000 [5:20:12<54:51,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 4820/5000 [6:00:56<13:21,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting Memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [6:14:30<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava:7b (Model 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [4:48:35<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: llava-llama3:8b (Model 3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 4951/5000 [4:11:45<03:15,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attempts failed for model llava-llama3:8b, row 11513. Storing default value.\n",
      "216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [4:14:14<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through models\n",
    "for index, model in enumerate(llms):\n",
    "    print(\"Processing Model: \" + model + \" (Model \" + str(index + 1) + \"/\" + str(len(llms)) + \")\")\n",
    "\n",
    "    # For each row\n",
    "    for index, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Predicting rows\"):  \n",
    "        # Memory leak fix\n",
    "        check_memory(model)   \n",
    "        \n",
    "        raw_response = None\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        \n",
    "        # Try up to 10 times\n",
    "        while attempts < 10 and not success:\n",
    "            try:\n",
    "                # Do the necessary image conversion\n",
    "                image = df_image_path_to_base64(row['image'])\n",
    "                \n",
    "                # Regress the price, get rid of commas and periods. Also stop when LLM returns any letter\n",
    "                raw_response = ollama.generate(model=model, prompt=prompt, images=[image], options={\"stop\": stop_chars})['response']\n",
    "                response = int(''.join(filter(str.isdigit, raw_response)))\n",
    "\n",
    "                # Raise an exception if the response is not between 10,000 and 10,000,000\n",
    "                if not (10000 <= response <= 10000000):\n",
    "                    raise ValueError(f\"Response value {response} is out of the acceptable range (10,000 to 10,000,000).\")\n",
    "\n",
    "                # Store response\n",
    "                df_test.at[index, f\"{model}_predicted_price\"] = response\n",
    "                success = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                \n",
    "        # If all attempts failed, store 550k (median)\n",
    "        if not success:\n",
    "            df_test.at[index, f\"{model}_predicted_price\"] = 550000\n",
    "            print(f\"All attempts failed for model {model}, row {index}. Storing default value.\")\n",
    "            print(raw_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f1d88b-766d-4a89-b107-36dcba728557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "      <th>gemma3:4b_predicted_price</th>\n",
       "      <th>llava:7b_predicted_price</th>\n",
       "      <th>llava-llama3:8b_predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "      <td>375000.0</td>\n",
       "      <td>123456.0</td>\n",
       "      <td>3000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>182000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>750000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  gemma3:4b_predicted_price  \\\n",
       "4772    houses_preprocessed/4793.jpg                   375000.0   \n",
       "3707    houses_preprocessed/3727.jpg                   285000.0   \n",
       "14159  houses_preprocessed/14333.jpg                   175000.0   \n",
       "6934    houses_preprocessed/7055.jpg                   675000.0   \n",
       "13453  houses_preprocessed/13627.jpg                   175000.0   \n",
       "\n",
       "       llava:7b_predicted_price  llava-llama3:8b_predicted_price  \n",
       "4772                   123456.0                        3000000.0  \n",
       "3707                   150000.0                         500000.0  \n",
       "14159                  182000.0                         500000.0  \n",
       "6934                   190000.0                         500000.0  \n",
       "13453                  510000.0                         750000.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353365f-aca1-402e-bf1a-b174271b8f88",
   "metadata": {},
   "source": [
    "### Calculate MAE for LLM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebedd6c0-b9cb-4bb2-8033-7bfced27228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model calculat MAE\n",
    "for model in llms:\n",
    "    # Column names per model\n",
    "    col_name = model + \"_predicted_price\"\n",
    "    mae_col_name = model + \"_\" + 'MAE'\n",
    "    \n",
    "    # Calculate absolute errors\n",
    "    df_test[mae_col_name] = abs(df_test['price'] - df_test[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c65b669b-9f8c-47b6-ad4f-5986fb6e0cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "      <th>gemma3:4b_predicted_price</th>\n",
       "      <th>llava:7b_predicted_price</th>\n",
       "      <th>llava-llama3:8b_predicted_price</th>\n",
       "      <th>gemma3:4b_MAE</th>\n",
       "      <th>llava:7b_MAE</th>\n",
       "      <th>llava-llama3:8b_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>-0.530372</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.473920</td>\n",
       "      <td>898000</td>\n",
       "      <td>houses_preprocessed/4793.jpg</td>\n",
       "      <td>375000.0</td>\n",
       "      <td>123456.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>523000.0</td>\n",
       "      <td>774544.0</td>\n",
       "      <td>2102000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1.018093</td>\n",
       "      <td>-0.489366</td>\n",
       "      <td>-0.472771</td>\n",
       "      <td>-0.753836</td>\n",
       "      <td>554900</td>\n",
       "      <td>houses_preprocessed/3727.jpg</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>269900.0</td>\n",
       "      <td>404900.0</td>\n",
       "      <td>54900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.477001</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>969000</td>\n",
       "      <td>houses_preprocessed/14333.jpg</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>182000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>794000.0</td>\n",
       "      <td>787000.0</td>\n",
       "      <td>469000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>0.145969</td>\n",
       "      <td>1.443367</td>\n",
       "      <td>0.570296</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>634900</td>\n",
       "      <td>houses_preprocessed/7055.jpg</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>40100.0</td>\n",
       "      <td>444900.0</td>\n",
       "      <td>134900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13453</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>-1.455732</td>\n",
       "      <td>-1.515838</td>\n",
       "      <td>-1.502881</td>\n",
       "      <td>397000</td>\n",
       "      <td>houses_preprocessed/13627.jpg</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>222000.0</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>353000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_citi       bed      bath      sqft   price  \\\n",
       "4772  -0.530372 -0.489366 -0.472771 -0.473920  898000   \n",
       "3707   1.018093 -0.489366 -0.472771 -0.753836  554900   \n",
       "14159 -1.286806  0.477001  0.570296  0.513102  969000   \n",
       "6934   0.145969  1.443367  0.570296  0.771561  634900   \n",
       "13453  0.341752 -1.455732 -1.515838 -1.502881  397000   \n",
       "\n",
       "                               image  gemma3:4b_predicted_price  \\\n",
       "4772    houses_preprocessed/4793.jpg                   375000.0   \n",
       "3707    houses_preprocessed/3727.jpg                   285000.0   \n",
       "14159  houses_preprocessed/14333.jpg                   175000.0   \n",
       "6934    houses_preprocessed/7055.jpg                   675000.0   \n",
       "13453  houses_preprocessed/13627.jpg                   175000.0   \n",
       "\n",
       "       llava:7b_predicted_price  llava-llama3:8b_predicted_price  \\\n",
       "4772                   123456.0                        3000000.0   \n",
       "3707                   150000.0                         500000.0   \n",
       "14159                  182000.0                         500000.0   \n",
       "6934                   190000.0                         500000.0   \n",
       "13453                  510000.0                         750000.0   \n",
       "\n",
       "       gemma3:4b_MAE  llava:7b_MAE  llava-llama3:8b_MAE  \n",
       "4772        523000.0      774544.0            2102000.0  \n",
       "3707        269900.0      404900.0              54900.0  \n",
       "14159       794000.0      787000.0             469000.0  \n",
       "6934         40100.0      444900.0             134900.0  \n",
       "13453       222000.0      113000.0             353000.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fe6eed-3a93-4ab0-9e0f-345e1fdcc50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n_citi', 'bed', 'bath', 'sqft', 'price', 'image',\n",
      "       'gemma3:4b_predicted_price', 'llava:7b_predicted_price',\n",
      "       'llava-llama3:8b_predicted_price', 'gemma3:4b_MAE', 'llava:7b_MAE',\n",
      "       'llava-llama3:8b_MAE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1cdd4-9f89-49bd-a569-27e7bc196b5d",
   "metadata": {},
   "source": [
    "# Train and Test models on the same data partioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c7e5e2-973a-419a-a8c5-4b1b2e64e71b",
   "metadata": {},
   "source": [
    "## Experimental set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6303daa6-f78a-4600-8571-b53dc0e2120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Tabular features: (10297, 4)\n",
      "Image features: (10297,)\n",
      "Target prices: (10297,)\n",
      "\n",
      "Test Data Shapes:\n",
      "Tabular features: (5000, 4)\n",
      "Image features: (5000,)\n",
      "Target prices: (5000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_tab = df_train[['n_citi', 'bed', 'bath', 'sqft']].values \n",
    "X_train_img = df_train['image']\n",
    "y_train = df_train['price']\n",
    "\n",
    "X_test_tab = df_test[['n_citi', 'bed', 'bath', 'sqft']].values \n",
    "X_test_img = df_test['image']\n",
    "y_test = df_test['price']\n",
    "\n",
    "print(\"Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab.shape}\")\n",
    "print(f\"Image features: {X_train_img.shape}\")\n",
    "print(f\"Target prices: {y_train.shape}\")\n",
    "\n",
    "print(\"\\nTest Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab.shape}\")\n",
    "print(f\"Image features: {X_test_img.shape}\")\n",
    "print(f\"Target prices: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b0e30-18bd-4942-bceb-4686c44b1857",
   "metadata": {},
   "source": [
    "## Creating Neural Networks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4051d7-42e9-4292-911c-71929f87c61f",
   "metadata": {},
   "source": [
    "### Base NN and Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b06b85f-735f-447c-8803-b0fc49ef9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn(image_shape=(311, 415, 3)):\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=image_shape, name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1)(x) # Regression output for price prediction\n",
    "\n",
    "    # Define the model\n",
    "    nn_model = Model(inputs=img_input, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd9bb4a2-e7b8-42a0-ab0c-db5edc4fca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_nn(image_shape=(311, 415, 3)):\n",
    "    # Image processing branch with pre-trained ResNet50\n",
    "    res_net = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "   \n",
    "    # Unfreeze only the last 10 layers of resnet (fine-tuning) \n",
    "    res_net.trainable = False \n",
    "    for layer in res_net.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=image_shape, name='image_input')\n",
    "    x = res_net(img_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1)(x) # Regression output for price prediction\n",
    "    \n",
    "    # Define the model\n",
    "    res_net_model = Model(inputs=img_input, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    res_net_model.compile(optimizer='adam', \n",
    "                          loss='mae',\n",
    "                          metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # res_net_model.summary()\n",
    "\n",
    "    return res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6986eb4-2d4a-4007-8e5c-5afa5bdd7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda img, lbl: process_example(img, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(nn, \n",
    "                          X_train_img_paths, y_train,\n",
    "                          X_test_img_paths, y_test,\n",
    "                          verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_robustified = create_dataset(X_train_img_paths, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_robustified = create_dataset(X_test_img_paths, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_robustified, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_robustified, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc38dd-c3ea-4b10-b68a-2175f8aa8a97",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5ec371-60b3-4846-a74b-d146da18afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lin_model(model, X_train_tab, y_train, X_test_tab, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_tab, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_test_pred = model.predict(X_test_tab)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return mae_test, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca49a9-1154-4503-b59f-0a4c6c0e299d",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc24bad-a953-49e2-ab67-cb1c07fc579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NNs (image only)\n",
    "nn_base = base_nn()\n",
    "nn_resnet = resnet_nn()\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a045bec4-8c81-41f1-8037-07c2b266fbb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 1s/step - R2Score: -1.3903 - loss: 444562.7500 - mae: 444562.7500\n",
      "Epoch 2/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 1s/step - R2Score: -0.1489 - loss: 287296.1875 - mae: 287296.1875\n",
      "Epoch 3/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1s/step - R2Score: -0.1465 - loss: 284436.2812 - mae: 284436.2812\n",
      "Epoch 4/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 1s/step - R2Score: -0.1307 - loss: 281265.2188 - mae: 281265.2188\n",
      "Epoch 5/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 1s/step - R2Score: -0.1233 - loss: 279358.1562 - mae: 279358.1562\n",
      "Epoch 6/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 1s/step - R2Score: -0.1020 - loss: 276307.0000 - mae: 276307.0000\n",
      "Epoch 7/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1s/step - R2Score: -0.1006 - loss: 280744.6562 - mae: 280744.6562\n",
      "Epoch 8/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 1s/step - R2Score: -0.0674 - loss: 276349.8438 - mae: 276349.8438\n",
      "Epoch 9/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1s/step - R2Score: -0.0417 - loss: 269582.0000 - mae: 269582.0000\n",
      "Epoch 10/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1s/step - R2Score: -0.0314 - loss: 267818.1562 - mae: 267818.1562\n",
      "Epoch 11/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1s/step - R2Score: -0.0350 - loss: 275005.6250 - mae: 275005.6250\n",
      "Epoch 12/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m782s\u001b[0m 1s/step - R2Score: -0.0295 - loss: 273810.3438 - mae: 273810.3438\n",
      "Epoch 13/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 1s/step - R2Score: -0.0216 - loss: 268256.1562 - mae: 268256.1562\n",
      "Epoch 14/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m769s\u001b[0m 1s/step - R2Score: -0.0273 - loss: 271658.1250 - mae: 271658.1250\n",
      "Epoch 15/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m856s\u001b[0m 1s/step - R2Score: -0.0257 - loss: 268492.9062 - mae: 268492.9062\n",
      "Epoch 16/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m879s\u001b[0m 1s/step - R2Score: -0.0318 - loss: 275516.7812 - mae: 275516.7812\n",
      "Epoch 17/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 1s/step - R2Score: -0.0311 - loss: 265380.4375 - mae: 265380.4375\n",
      "Epoch 18/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 1s/step - R2Score: -0.0289 - loss: 270896.8750 - mae: 270896.8750\n",
      "Epoch 19/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m870s\u001b[0m 1s/step - R2Score: -0.0209 - loss: 270241.2500 - mae: 270241.2500\n",
      "Epoch 20/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 1s/step - R2Score: -0.0221 - loss: 266905.7812 - mae: 266905.7812\n",
      "Epoch 21/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m845s\u001b[0m 1s/step - R2Score: -0.0223 - loss: 265181.1562 - mae: 265181.1562\n",
      "Epoch 22/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 1s/step - R2Score: -0.0139 - loss: 267405.0000 - mae: 267405.0000\n",
      "Epoch 23/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 1s/step - R2Score: -0.0230 - loss: 268119.9688 - mae: 268119.9688\n",
      "Epoch 24/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 1s/step - R2Score: -0.0228 - loss: 274064.8750 - mae: 274064.8750\n",
      "Epoch 25/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 1s/step - R2Score: -0.0166 - loss: 269064.5312 - mae: 269064.5312\n",
      "NN Base MAE: 264775\n",
      "NN Base R2: -0.01\n",
      "WARNING:tensorflow:From C:\\Users\\danie\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "print(\"Training Base NN\")\n",
    "nn_base_hist, _, nn_base_mae, nn_base_r2 = train_and_evaluate_nn(nn_base, X_train_img, y_train, X_test_img, y_test)\n",
    "print(f\"NN Base MAE: {nn_base_mae:.0f}\\nNN Base R2: {nn_base_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d8ced1b-fe4a-4d18-96dc-306c6f6d2a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1681s\u001b[0m 3s/step - R2Score: -3.3015 - loss: 693742.5000 - mae: 693742.5000\n",
      "Epoch 2/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1694s\u001b[0m 3s/step - R2Score: -1.4881 - loss: 462300.3125 - mae: 462300.3125\n",
      "Epoch 3/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1721s\u001b[0m 3s/step - R2Score: 0.0532 - loss: 260306.7812 - mae: 260306.7812\n",
      "Epoch 4/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1716s\u001b[0m 3s/step - R2Score: 0.0597 - loss: 256366.4062 - mae: 256366.4062\n",
      "Epoch 5/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 3s/step - R2Score: 0.0691 - loss: 257995.2969 - mae: 257995.2969\n",
      "Epoch 6/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1728s\u001b[0m 3s/step - R2Score: 0.0806 - loss: 256774.9844 - mae: 256774.9844\n",
      "Epoch 7/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1724s\u001b[0m 3s/step - R2Score: 0.0939 - loss: 249597.5000 - mae: 249597.5000\n",
      "Epoch 8/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1727s\u001b[0m 3s/step - R2Score: 0.0870 - loss: 248342.0469 - mae: 248342.0469\n",
      "Epoch 9/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1719s\u001b[0m 3s/step - R2Score: 0.1052 - loss: 245255.2344 - mae: 245255.2344\n",
      "Epoch 10/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 3s/step - R2Score: 0.1096 - loss: 248626.7969 - mae: 248626.7969\n",
      "Epoch 11/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1732s\u001b[0m 3s/step - R2Score: 0.1140 - loss: 245240.5000 - mae: 245240.5000\n",
      "Epoch 12/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1723s\u001b[0m 3s/step - R2Score: 0.1264 - loss: 245299.1250 - mae: 245299.1250\n",
      "Epoch 13/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1729s\u001b[0m 3s/step - R2Score: 0.1267 - loss: 243219.6250 - mae: 243219.6250\n",
      "Epoch 14/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1729s\u001b[0m 3s/step - R2Score: 0.1364 - loss: 243433.0781 - mae: 243433.0781\n",
      "Epoch 15/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1718s\u001b[0m 3s/step - R2Score: 0.1205 - loss: 245882.6562 - mae: 245882.6562\n",
      "Epoch 16/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1730s\u001b[0m 3s/step - R2Score: 0.1392 - loss: 237582.3281 - mae: 237582.3281\n",
      "Epoch 17/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1716s\u001b[0m 3s/step - R2Score: 0.1509 - loss: 242999.0469 - mae: 242999.0469\n",
      "Epoch 18/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1723s\u001b[0m 3s/step - R2Score: 0.1558 - loss: 238161.6875 - mae: 238161.6875\n",
      "Epoch 19/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1725s\u001b[0m 3s/step - R2Score: 0.1528 - loss: 233542.9844 - mae: 233542.9844\n",
      "Epoch 20/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1719s\u001b[0m 3s/step - R2Score: 0.1763 - loss: 236630.0469 - mae: 236630.0469\n",
      "Epoch 21/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1712s\u001b[0m 3s/step - R2Score: 0.1773 - loss: 234808.2812 - mae: 234808.2812\n",
      "Epoch 22/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 3s/step - R2Score: 0.1887 - loss: 235953.0781 - mae: 235953.0781\n",
      "Epoch 23/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1721s\u001b[0m 3s/step - R2Score: 0.1740 - loss: 228152.0469 - mae: 228152.0469\n",
      "Epoch 24/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1740s\u001b[0m 3s/step - R2Score: 0.1961 - loss: 232806.1406 - mae: 232806.1406\n",
      "Epoch 25/25\n",
      "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1734s\u001b[0m 3s/step - R2Score: 0.1996 - loss: 231294.0469 - mae: 231294.0469\n",
      "Resnet MAE: 316761\n",
      "Resnet R2: -0.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet\n",
    "print(\"Training Resnet\")\n",
    "nn_resnet_hist, _, nn_resnet_mae, nn_resnet_r2 = train_and_evaluate_nn(nn_resnet, X_train_img, y_train, X_test_img, y_test)\n",
    "print(f\"Resnet MAE: {nn_resnet_mae:.0f}\\nResnet R2: {nn_resnet_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4a772e2-7026-4c46-a068-922f8990d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "LR MAE: 223193\n",
      "LR R2: 0.34\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "print(\"Training LR\")\n",
    "lr_mae, lr_r2 = train_and_evaluate_lin_model(lin, X_train_tab, y_train, X_test_tab, y_test)\n",
    "print(f\"LR MAE: {lr_mae:.0f}\\nLR R2: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1aee6f-72d3-4721-bd32-74731acf34f1",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "155d61f3-0f25-49f2-88b9-b3d7eff710ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llava:7b</th>\n",
       "      <td>484657</td>\n",
       "      <td>-1.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava-llama3:8b</th>\n",
       "      <td>623507</td>\n",
       "      <td>-10.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma3:4b</th>\n",
       "      <td>304654</td>\n",
       "      <td>-0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_base</th>\n",
       "      <td>264775</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_ResNet</th>\n",
       "      <td>316761</td>\n",
       "      <td>-0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>223193</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MAE      R2\n",
       "Model                          \n",
       "llava:7b         484657  -1.977\n",
       "llava-llama3:8b  623507 -10.402\n",
       "gemma3:4b        304654  -0.265\n",
       "NN_base          264775  -0.005\n",
       "NN_ResNet        316761  -0.434\n",
       "LR               223193   0.341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAEs\n",
    "llava_7b_MAE = df_test['llava:7b_MAE'].mean()\n",
    "llava_llama3_8b_MAE = df_test['llava-llama3:8b_MAE'].mean()\n",
    "gemma3_4b_MAE = df_test['gemma3:4b_MAE'].mean()\n",
    "\n",
    "# R2s\n",
    "llava_7b_r2 = r2_score(df_test['price'], df_test['llava:7b_predicted_price'])\n",
    "llava_llama3_8b_r2 = r2_score(df_test['price'], df_test['llava-llama3:8b_predicted_price'])\n",
    "gemma3_4b_r2 = r2_score(df_test['price'], df_test['gemma3:4b_predicted_price'])\n",
    "\n",
    "# Create a dictionary with the model names and their performance metrics\n",
    "comparison = {\n",
    "    'Model': ['llava:7b', 'llava-llama3:8b', 'gemma3:4b', 'NN_base', 'NN_ResNet', 'LR'],\n",
    "    'MAE': [\n",
    "        round(llava_7b_MAE),\n",
    "        round(llava_llama3_8b_MAE),\n",
    "        round(gemma3_4b_MAE),\n",
    "        round(nn_base_mae),\n",
    "        round(nn_resnet_mae),\n",
    "        round(lr_mae)\n",
    "    ],\n",
    "    'R2': [\n",
    "        round(llava_7b_r2, 3),\n",
    "        round(llava_llama3_8b_r2, 3),\n",
    "        round(gemma3_4b_r2, 3),\n",
    "        round(nn_base_r2, 3),\n",
    "        round(nn_resnet_r2, 3),\n",
    "        round(lr_r2, 3)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Make into df\n",
    "comparison_df = pd.DataFrame(comparison).set_index(\"Model\")\n",
    "display(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
