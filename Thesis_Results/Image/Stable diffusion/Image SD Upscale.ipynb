{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a29a8-299e-40e1-a74e-1582d18d83fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82983fac-5b01-4856-b440-abbcf7104c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Roaming\\Python\\Python312\\site-packages\\RealESRGAN\\model.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Concatenate, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import torch\n",
    "from RealESRGAN import RealESRGAN\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1c425-de82-4e64-a2e5-91656221d3bb",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cf5bca-5c72-4f2b-add9-759af2581f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to upscale by RealESRGAN\n",
    "n_rows = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc3b83b-5277-4f26-81c8-5e6d72911ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing scale\n",
    "scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11db700-611a-4a2d-a854-eae7cba070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Parameters\n",
    "epochs = 25\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bdb00-4a1f-4d9b-b80e-226d6ae20a8a",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00581dd5-5962-40e6-b313-612d4da96b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample n_rows worth of data\n",
    "work_df, _ = train_test_split(pd.read_csv(\"houses_preprocessed.csv\"), train_size=n_rows, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9898847-adf5-4015-b9ab-ec33fc794be1",
   "metadata": {},
   "source": [
    "# Image Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e00b4c-b2ed-4502-995e-e25386bca984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Roaming\\Python\\Python312\\site-packages\\RealESRGAN\\model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loadnet = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Load RealESRGAN_x4\n",
    "model_id = \"RealESRGAN_x4\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else None)\n",
    "model = RealESRGAN(device, scale=scale)\n",
    "model.load_weights('weights/RealESRGAN_x4.pth', download=False) # Needs only be done once\n",
    "\n",
    "# Create output directory\n",
    "model_output_dir = os.path.join(\"Images Upscaled\", f\"{model_id}\")\n",
    "os.makedirs(model_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a27e89-fc8c-4a3c-8ee3-1be4c260f988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upscaling Images: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [45:07<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Upscaling Images\n",
    "for index, row in tqdm(work_df.iterrows(), total=n_rows, desc=\"Upscaling Images\"):   \n",
    "    # Load the image to be upscaled\n",
    "    input_image = Image.open(row[\"image\"]).convert(\"RGB\")\n",
    "\n",
    "    # Predict using RealESRGAN\n",
    "    RealESRGAN_resize = model.predict(input_image)\n",
    "    \n",
    "    # LANCZOS resizing\n",
    "    # Calculate the upscale dimensions\n",
    "    original_width, original_height = input_image.size\n",
    "    output_width = original_width * scale\n",
    "    output_height = original_height * scale\n",
    "    traditional_resize = input_image.resize((output_width, output_height), Image.LANCZOS)\n",
    "           \n",
    "    # Save the result\n",
    "    RealESRGAN_resize.save(os.path.join(model_output_dir, f\"{index}_{row['price']}_RealESRGAN.jpg\"))\n",
    "    traditional_resize.save(os.path.join(model_output_dir, f\"{index}_{row['price']}_lanczos.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484a427-3ab5-4a4f-958c-b59e26c5f6cf",
   "metadata": {},
   "source": [
    "# Experimental set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ded195-dc21-4ca2-9bc9-788114c15c7d",
   "metadata": {},
   "source": [
    "## Train and Test the models on the same data partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dfb3eec-0910-458d-9204-59a153899324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Tabular features: (2000, 4)\n",
      "Image features: (2000,)\n",
      "Target prices: (2000,)\n",
      "\n",
      "Test Data Shapes:\n",
      "Tabular features: (500, 4)\n",
      "Image features: (500,)\n",
      "Target prices: (500,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "train, test = train_test_split(work_df, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Train data\n",
    "X_train_tab = train[['n_citi', 'bed', 'bath', 'sqft']].values \n",
    "X_train_img = train['image'] # pd\n",
    "y_train = train['price']\n",
    "\n",
    "# Test data ith compression cols\n",
    "X_test_tab = test[['n_citi', 'bed', 'bath', 'sqft']].values \n",
    "X_test_img = test['image'] # pd\n",
    "y_test = test['price']\n",
    "\n",
    "# Print shapes\n",
    "print(\"Training Data Shapes:\")\n",
    "print(f\"Tabular features: {X_train_tab.shape}\")\n",
    "print(f\"Image features: {X_train_img.shape}\")\n",
    "print(f\"Target prices: {y_train.shape}\")\n",
    "print(\"\\nTest Data Shapes:\")\n",
    "print(f\"Tabular features: {X_test_tab.shape}\")\n",
    "print(f\"Image features: {X_test_img.shape}\")\n",
    "print(f\"Target prices: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48ff29-ea29-4c05-bc75-1a88affe93a5",
   "metadata": {},
   "source": [
    "# Neural Networks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4051d7-42e9-4292-911c-71929f87c61f",
   "metadata": {},
   "source": [
    "## Base NN and Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a0b040-e9ae-4980-a338-f186ae2559b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_nn(image_shape=(311, 415, 3)):\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=image_shape, name='image_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1)(x) # Regression output for price prediction\n",
    "\n",
    "    # Define the model\n",
    "    nn_model = Model(inputs=img_input, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # nn_model.summary()\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e67de0c-9641-481d-b8f9-0a495c239ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_nn(image_shape=(311, 415, 3)):\n",
    "    # Image processing branch with pre-trained ResNet50\n",
    "    res_net = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "   \n",
    "    # Unfreeze only the last 10 layers of resnet (fine-tuning) \n",
    "    res_net.trainable = False \n",
    "    for layer in res_net.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Image processing branch\n",
    "    img_input = Input(shape=image_shape, name='image_input')\n",
    "    x = res_net(img_input)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1)(x) # Regression output for price prediction\n",
    "    \n",
    "    # Define the model\n",
    "    res_net_model = Model(inputs=img_input, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    res_net_model.compile(optimizer='adam', \n",
    "                          loss='mae',\n",
    "                          metrics=['mae', 'R2Score'])\n",
    "    \n",
    "    # Display model summary debug\n",
    "    # res_net_model.summary()\n",
    "\n",
    "    return res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6986eb4-2d4a-4007-8e5c-5afa5bdd7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I did not write this code, the code is from: https://www.tensorflow.org/tutorials/load_data/images\n",
    "It helps us train the NN more dynamically, it loads images on the go, such that not all RAM is used up.\n",
    "It does try to maximise RAM usage this is basically what the tf.data.AUTOTUNE does.\n",
    "'''\n",
    "\n",
    "# Loads an image and normalizes it from [0,1]\n",
    "def process_example(image_path, label):\n",
    "    # Load raw bytes and convert to RGB\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Normalize image to [0, 1] and convert to float32\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Creates on the fly data sets to train/test the model, we need this to not exceed memory\n",
    "def create_dataset(image_paths, labels, shuffle=True):\n",
    "    # Convert to tensors\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    # Build dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda img, lbl: process_example(img, lbl), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_and_evaluate_nn(nn, \n",
    "                          X_train_img_paths, y_train,\n",
    "                          X_test_img_paths, y_test,\n",
    "                          verbose=1):\n",
    "\n",
    "    # Dynamic dataset loading\n",
    "    train_upscale = create_dataset(X_train_img_paths, y_train, shuffle=True) # Shuffle to break ordering\n",
    "    test_upscale = create_dataset(X_test_img_paths, y_test, shuffle=False) # No shuffle, we arent learning, just predicting\n",
    "\n",
    "    # Train and Test\n",
    "    history = nn.fit(train_upscale, epochs=epochs, verbose=verbose)\n",
    "    test_loss, test_mae, r2 = nn.evaluate(test_upscale, verbose=0)\n",
    "\n",
    "    return history, test_loss, test_mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1130b83-5ff9-4e2e-ae9e-b3120199c078",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9420a061-071f-42ca-9fa0-6a786483c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lin_model(model, X_train_tab, y_train, X_test_tab, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_tab, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_test_pred = model.predict(X_test_tab)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return mae_test, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e77cd4-cbce-4196-9807-81c9dd7f2de7",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ca542d-f810-453e-88f6-9980e9d31c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create NNs with tabular features = 4 (n_citi, bed, bath, sqft)\n",
    "nn_base = base_nn()\n",
    "nn_resnet = resnet_nn()\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0bc0e7b-ba87-486f-9c72-087f6fbcc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_image_shapes(expected_image_res, xtrain, xtest):\n",
    "    # Check training set sample\n",
    "    train_sample_path = xtrain.iloc[0] # Get first training image\n",
    "    train_img = np.array(Image.open(train_sample_path))\n",
    "    assert train_img.shape == expected_image_res\n",
    "    \n",
    "    # Check test set sample\n",
    "    test_sample_path = xtest.iloc[0]  # Get first test image\n",
    "    test_img = np.array(Image.open(test_sample_path))\n",
    "    assert test_img.shape == expected_image_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b05f73-f032-4471-8606-992c86d5e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_image_shapes((311, 415, 3), X_train_img, X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc0de7c0-89ba-420b-87bc-307d37b0cbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - R2Score: -3.2351 - loss: 646451.3750 - mae: 646451.3750\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1751 - loss: 279172.6562 - mae: 279172.6562\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1458 - loss: 268616.1250 - mae: 268616.1250\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1460 - loss: 275600.6562 - mae: 275600.6562\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - R2Score: -0.1360 - loss: 274374.8125 - mae: 274374.8125\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1698 - loss: 278471.5000 - mae: 278471.5000\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1476 - loss: 288671.0625 - mae: 288671.0625\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1278 - loss: 274205.3125 - mae: 274205.3125\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1442 - loss: 275325.2812 - mae: 275325.2812\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1445 - loss: 272260.3438 - mae: 272260.3438\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1588 - loss: 280069.0938 - mae: 280069.0938\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - R2Score: -0.1449 - loss: 277660.9688 - mae: 277660.9688\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1005 - loss: 260914.7500 - mae: 260914.7500\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - R2Score: -0.1425 - loss: 273737.8750 - mae: 273737.8750\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - R2Score: -0.1198 - loss: 276520.0938 - mae: 276520.0938\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1165 - loss: 286345.0000 - mae: 286345.0000\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1298 - loss: 270705.0625 - mae: 270705.0625\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1373 - loss: 285972.6875 - mae: 285972.6875\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1248 - loss: 273774.7500 - mae: 273774.7500\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1170 - loss: 271841.5938 - mae: 271841.5938\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1245 - loss: 271957.7812 - mae: 271957.7812\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - R2Score: -0.1114 - loss: 274034.7812 - mae: 274034.7812\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - R2Score: -0.1239 - loss: 272228.9375 - mae: 272228.9375\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1078 - loss: 283069.4062 - mae: 283069.4062\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - R2Score: -0.1116 - loss: 270685.9062 - mae: 270685.9062\n",
      "NN Base MAE: 305006\n",
      "NN Base R2: -0.13\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "print(\"Training Base NN\")\n",
    "nn_base_hist, _, nn_base_mae, nn_base_r2 = train_and_evaluate_nn(nn_base, X_train_img, y_train, X_test_img, y_test)\n",
    "print(f\"NN Base MAE: {nn_base_mae:.0f}\\nNN Base R2: {nn_base_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a444f6e-80cb-425e-8c7c-e506a01e1810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 3s/step - R2Score: -3.4810 - loss: 698828.4375 - mae: 698828.4375\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -3.4772 - loss: 685783.6250 - mae: 685783.6250\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: -3.1858 - loss: 683771.9375 - mae: 683771.9375\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -3.0321 - loss: 650369.5000 - mae: 650369.5000\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -2.5197 - loss: 598489.8750 - mae: 598489.8750\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - R2Score: -2.2229 - loss: 526674.0000 - mae: 526674.0000\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -1.3663 - loss: 437473.5625 - mae: 437473.5625\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -0.4750 - loss: 313160.4062 - mae: 313160.4062\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: -0.1236 - loss: 270224.9688 - mae: 270224.9688\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0205 - loss: 249772.3906 - mae: 249772.3906\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0581 - loss: 245596.8125 - mae: 245596.8125\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0702 - loss: 243947.1406 - mae: 243947.1406\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0850 - loss: 243068.5469 - mae: 243068.5469\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: 0.0624 - loss: 247919.3594 - mae: 247919.3594\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0879 - loss: 251316.9688 - mae: 251316.9688\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.0973 - loss: 249126.7031 - mae: 249126.7031\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.1208 - loss: 237959.5781 - mae: 237959.5781\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.1458 - loss: 231238.6094 - mae: 231238.6094\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.1329 - loss: 231996.7188 - mae: 231996.7188\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: 0.1632 - loss: 227611.0469 - mae: 227611.0469\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: 0.1360 - loss: 223516.5000 - mae: 223516.5000\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: 0.1493 - loss: 222812.8281 - mae: 222812.8281\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.1440 - loss: 228188.4375 - mae: 228188.4375\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - R2Score: 0.1824 - loss: 226584.2500 - mae: 226584.2500\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - R2Score: 0.1788 - loss: 223266.9219 - mae: 223266.9219\n",
      "Resnet MAE: 514309\n",
      "Resnet R2: -1.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet\n",
    "print(\"Training Resnet\")\n",
    "nn_resnet_hist, _, nn_resnet_mae, nn_resnet_r2 = train_and_evaluate_nn(nn_resnet, X_train_img, y_train, X_test_img, y_test)\n",
    "print(f\"Resnet MAE: {nn_resnet_mae:.0f}\\nResnet R2: {nn_resnet_r2:.2f}\")\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ab7bff-d3f9-40d1-822f-97ed37cae254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "LR MAE: 234918\n",
      "LR R2: 0.40\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "print(\"Training LR\")\n",
    "lr_mae, lr_r2 = train_and_evaluate_lin_model(lin, X_train_tab, y_train, X_test_tab, y_test)\n",
    "print(f\"LR MAE: {lr_mae:.0f}\\nLR R2: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c429bd-01c4-4578-afd1-c4ffea114274",
   "metadata": {},
   "source": [
    "# Comparison Upscaled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8039552a-3826-462c-81ab-4a30bc584932",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method input should be x train, y train, x test and y test.\n",
    "Then hardcopy and return the x train image with the upscale method\n",
    "return train test split x and y upscaled method image\n",
    "'''\n",
    "def load_upscale_data(upscale_method, xtrain, xtest):   \n",
    "    # Load image paths and prices\n",
    "    image_path = f\"Images Upscaled/RealESRGAN_x4\"\n",
    "    X_train_upscale = []\n",
    "    y_train_upscale = []\n",
    "    X_test_upscale = []\n",
    "    y_test_upscale = []   \n",
    "\n",
    "    # For each image in directory\n",
    "    for img_file in os.listdir(image_path):\n",
    "        # Only take either the images generated by either realesrgan or lanczos\n",
    "        if upscale_method in img_file:\n",
    "            # Images have format: \"i_price_upscaleMethod.jpg\")\n",
    "            image_id, image_price, upscale_method_img = img_file.split('_')\n",
    "            image_id, image_price = (int(image_id), int(image_price)) # Cast to int\n",
    "            assert upscale_method == upscale_method_img.strip(\".jpg\")\n",
    "\n",
    "            # If in X_train add to X_upscale, vice versa y\n",
    "            if image_id in xtrain.index:\n",
    "                X_train_upscale.append(image_path + \"/\" + img_file)\n",
    "                y_train_upscale.append(image_price)\n",
    "            elif image_id in xtest.index: \n",
    "                X_test_upscale.append(image_path + \"/\" + img_file)\n",
    "                y_test_upscale.append(image_price)\n",
    "            else:\n",
    "                raise Exception(\"Image ID not found\")\n",
    "    \n",
    "    # Ensure loaded images match the expected number of upscaled images\n",
    "    assert len(X_train_upscale) + len(X_test_upscale) == n_rows\n",
    "    assert len(y_train_upscale) + len(y_test_upscale) == n_rows\n",
    "\n",
    "    return X_train_upscale, y_train_upscale, X_test_upscale, y_test_upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae01a21-8e4d-4244-847d-f095285c88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison(llm, model_results):\n",
    "    # DF Structure\n",
    "    comparison_data = {\n",
    "        'Model': [],\n",
    "        'MAE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "    \n",
    "    for model_name, mae, r2 in model_results:\n",
    "        comparison_data['Model'].append(model_name)\n",
    "        comparison_data['MAE'].append(round(mae))\n",
    "        comparison_data['R2'].append(round(r2, 3))\n",
    "    \n",
    "    # Make into df\n",
    "    comparison_df = pd.DataFrame(comparison_data).set_index(\"Model\")\n",
    "    \n",
    "    # Display df\n",
    "    print(f\"Comparison of Models for {llm}\")\n",
    "    display(comparison_df)\n",
    "    print()\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248d751d-2095-48fa-9bd1-5cc96f382f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shapes(xtrain, ytrain, xtest, ytest):\n",
    "    # Print shapes\n",
    "    print(\"Training Data Shapes:\")\n",
    "    print(f\"Features: {len(xtrain)}\")\n",
    "    print(f\"Target prices: {len(ytrain)}\")\n",
    "    print(\"\\nTest Data Shapes:\")\n",
    "    print(f\"Features: {len(xtest)}\")\n",
    "    print(f\"Target prices: {len(ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d4bee6e-b1ea-482b-9801-0c302ac1de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_image_shapes_lst(expected_image_res, xtrain, xtest):\n",
    "    # Check training set sample\n",
    "    train_sample_path = xtrain[0] # Get first training image\n",
    "    train_img = np.array(Image.open(train_sample_path))\n",
    "    assert train_img.shape == expected_image_res\n",
    "    \n",
    "    # Check test set sample\n",
    "    test_sample_path = xtest[0]  # Get first test image\n",
    "    test_img = np.array(Image.open(test_sample_path))\n",
    "    assert test_img.shape == expected_image_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02ce81c7-0b49-4125-8607-b2e695de1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Supress retracing warning\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # '0' = all messages, '3' = fatal only\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "278b4752-4d09-49e9-8da3-5b73a711384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store results\n",
    "model_results = []\n",
    "\n",
    "# Store default results\n",
    "model_results.append(('NN Base', nn_base_mae, nn_base_r2))\n",
    "model_results.append(('NN Resnet', nn_resnet_mae, nn_resnet_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77328c9-8276-4509-af80-2db59a707327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Features: 2000\n",
      "Target prices: 2000\n",
      "\n",
      "Test Data Shapes:\n",
      "Features: 500\n",
      "Target prices: 500\n",
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 6s/step - R2Score: -3.1025 - loss: 649290.8125 - mae: 649290.8125\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 6s/step - R2Score: -0.1817 - loss: 285212.7500 - mae: 285212.7500\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 6s/step - R2Score: -0.1525 - loss: 283796.6562 - mae: 283796.6562\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 6s/step - R2Score: -0.1143 - loss: 272049.2188 - mae: 272049.2188\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 6s/step - R2Score: -0.1579 - loss: 281113.3125 - mae: 281113.3125\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 6s/step - R2Score: -0.1491 - loss: 270548.7812 - mae: 270548.7812\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m873s\u001b[0m 6s/step - R2Score: -0.1527 - loss: 285588.4375 - mae: 285588.4375\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m845s\u001b[0m 6s/step - R2Score: -0.1208 - loss: 276273.6250 - mae: 276273.6250\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m815s\u001b[0m 6s/step - R2Score: -0.1420 - loss: 275242.4375 - mae: 275242.4375\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 6s/step - R2Score: -0.1234 - loss: 268116.6875 - mae: 268116.6875\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 6s/step - R2Score: -0.1286 - loss: 284097.1562 - mae: 284097.1562\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 6s/step - R2Score: -0.1401 - loss: 277797.6562 - mae: 277797.6562\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 6s/step - R2Score: -0.1417 - loss: 273278.9375 - mae: 273278.9375\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m876s\u001b[0m 6s/step - R2Score: -0.1246 - loss: 269688.4375 - mae: 269688.4375\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m857s\u001b[0m 6s/step - R2Score: -0.1353 - loss: 282983.4375 - mae: 282983.4375\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 6s/step - R2Score: -0.1135 - loss: 278356.6875 - mae: 278356.6875\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 6s/step - R2Score: -0.1198 - loss: 269977.5625 - mae: 269977.5625\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m851s\u001b[0m 6s/step - R2Score: -0.1281 - loss: 282358.5000 - mae: 282358.5000\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 6s/step - R2Score: -0.1101 - loss: 277157.4062 - mae: 277157.4062\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 6s/step - R2Score: -0.1098 - loss: 278826.7188 - mae: 278826.7188\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 6s/step - R2Score: -0.1345 - loss: 275925.7500 - mae: 275925.7500\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 6s/step - R2Score: -0.1254 - loss: 279971.4688 - mae: 279971.4688\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 6s/step - R2Score: -0.1086 - loss: 272921.1562 - mae: 272921.1562\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m870s\u001b[0m 6s/step - R2Score: -0.0985 - loss: 272767.2188 - mae: 272767.2188\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 6s/step - R2Score: -0.1016 - loss: 273298.1250 - mae: 273298.1250\n",
      "Training Resnet NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1433s\u001b[0m 10s/step - R2Score: -3.5593 - loss: 676198.3750 - mae: 676198.3750\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1297s\u001b[0m 10s/step - R2Score: -3.5588 - loss: 684830.8750 - mae: 684830.8750\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 10s/step - R2Score: -3.6649 - loss: 685231.5000 - mae: 685231.5000\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1289s\u001b[0m 10s/step - R2Score: -3.2044 - loss: 682154.2500 - mae: 682154.2500\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1297s\u001b[0m 10s/step - R2Score: -2.8699 - loss: 609662.1875 - mae: 609662.1875\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1295s\u001b[0m 10s/step - R2Score: -2.3350 - loss: 553248.4375 - mae: 553248.4375\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 10s/step - R2Score: -1.5560 - loss: 473585.4375 - mae: 473585.4375\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1293s\u001b[0m 10s/step - R2Score: -0.8638 - loss: 362749.2500 - mae: 362749.2500\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1288s\u001b[0m 10s/step - R2Score: -0.2661 - loss: 288056.4062 - mae: 288056.4062\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1281s\u001b[0m 10s/step - R2Score: -0.0522 - loss: 266685.3438 - mae: 266685.3438\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1283s\u001b[0m 10s/step - R2Score: 0.0166 - loss: 261166.1719 - mae: 261166.1719\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1286s\u001b[0m 10s/step - R2Score: 0.0344 - loss: 254942.7656 - mae: 254942.7656\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1283s\u001b[0m 10s/step - R2Score: 0.0620 - loss: 246345.8906 - mae: 246345.8906\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 10s/step - R2Score: 0.0513 - loss: 244624.1562 - mae: 244624.1562\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1288s\u001b[0m 10s/step - R2Score: 0.0542 - loss: 252969.1875 - mae: 252969.1875\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1284s\u001b[0m 10s/step - R2Score: 0.0590 - loss: 241330.8906 - mae: 241330.8906\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1279s\u001b[0m 10s/step - R2Score: 0.0431 - loss: 249551.9844 - mae: 249551.9844\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 10s/step - R2Score: 0.0835 - loss: 245175.6875 - mae: 245175.6875\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 10s/step - R2Score: 0.0519 - loss: 251184.6719 - mae: 251184.6719\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1282s\u001b[0m 10s/step - R2Score: 0.0593 - loss: 247656.2031 - mae: 247656.2031\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 10s/step - R2Score: 0.1130 - loss: 242832.3594 - mae: 242832.3594\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1281s\u001b[0m 10s/step - R2Score: 0.1154 - loss: 243286.6094 - mae: 243286.6094\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1284s\u001b[0m 10s/step - R2Score: 0.1245 - loss: 227684.4219 - mae: 227684.4219\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1279s\u001b[0m 10s/step - R2Score: 0.0904 - loss: 241480.9219 - mae: 241480.9219\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 10s/step - R2Score: 0.0916 - loss: 238570.5469 - mae: 238570.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lanczos\n",
    "# Load upscaled images\n",
    "X_train_upscale_lanczos, y_train_upscale_lanczos, X_test_upscale_lanczos, y_test_upscale_lanczos = load_upscale_data('lanczos', X_train_img, X_test_img)\n",
    "\n",
    "# Debug\n",
    "print_shapes(X_train_upscale_lanczos, y_train_upscale_lanczos, X_test_upscale_lanczos, y_test_upscale_lanczos)\n",
    "assert_image_shapes_lst((311*scale, 415*scale, 3), X_train_upscale_lanczos, X_test_upscale_lanczos)\n",
    "\n",
    "# Create, Train and Evaluate the models\n",
    "nn_base_upscale_lanczos = base_nn((311*scale, 415*scale, 3))\n",
    "nn_resnet_upscale_lanczos = resnet_nn((311*scale, 415*scale, 3))\n",
    "\n",
    "print(\"Training Base NN\")\n",
    "_, _, nn_base_upscale_mae_lanczos, nn_base_upscale_r2_lanczos = train_and_evaluate_nn(nn_base_upscale_lanczos, \n",
    "                                                                      X_train_upscale_lanczos, y_train_upscale_lanczos, \n",
    "                                                                      X_test_upscale_lanczos, y_test_upscale_lanczos)\n",
    "print(\"Training Resnet NN\")\n",
    "_, _, nn_resnet_upscale_mae_lanczos, nn_resnet_upscale_r2_lanczos = train_and_evaluate_nn(nn_resnet_upscale_lanczos, \n",
    "                                                                                          X_train_upscale_lanczos, y_train_upscale_lanczos, \n",
    "                                                                                          X_test_upscale_lanczos, y_test_upscale_lanczos)\n",
    "\n",
    "# Store results for both models\n",
    "model_results.append((\"NN Base Upscaled \" + 'lanczos', nn_base_upscale_mae_lanczos, nn_base_upscale_r2_lanczos))\n",
    "model_results.append((\"NN Resnet Upscaled \" + 'lanczos', nn_resnet_upscale_mae_lanczos, nn_resnet_upscale_r2_lanczos))\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "539c3865-31cd-4b17-8c54-6237e5eaaac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shapes:\n",
      "Features: 2000\n",
      "Target prices: 2000\n",
      "\n",
      "Test Data Shapes:\n",
      "Features: 500\n",
      "Target prices: 500\n",
      "Training Base NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 6s/step - R2Score: -3.3778 - loss: 653327.4375 - mae: 653327.4375\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 6s/step - R2Score: -0.1929 - loss: 280087.4375 - mae: 280087.4375\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 6s/step - R2Score: -0.1189 - loss: 276370.5000 - mae: 276370.5000\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 6s/step - R2Score: -0.1519 - loss: 296378.0000 - mae: 296378.0000\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 6s/step - R2Score: -0.1588 - loss: 269393.4375 - mae: 269393.4375\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m844s\u001b[0m 6s/step - R2Score: -0.1487 - loss: 269432.5000 - mae: 269432.5000\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 6s/step - R2Score: -0.1443 - loss: 276236.7188 - mae: 276236.7188\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 6s/step - R2Score: -0.1295 - loss: 266526.0312 - mae: 266526.0312\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m906s\u001b[0m 6s/step - R2Score: -0.1423 - loss: 277622.3438 - mae: 277622.3438\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m784s\u001b[0m 6s/step - R2Score: -0.1554 - loss: 288106.4062 - mae: 288106.4062\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 6s/step - R2Score: -0.1452 - loss: 276603.4688 - mae: 276603.4688\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 6s/step - R2Score: -0.1678 - loss: 291370.2500 - mae: 291370.2500\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 6s/step - R2Score: -0.1186 - loss: 268747.9375 - mae: 268747.9375\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 6s/step - R2Score: -0.1373 - loss: 272712.1875 - mae: 272712.1875\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 6s/step - R2Score: -0.1246 - loss: 269398.4688 - mae: 269398.4688\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 6s/step - R2Score: -0.1215 - loss: 278259.6562 - mae: 278259.6562\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 6s/step - R2Score: -0.1233 - loss: 275000.8750 - mae: 275000.8750\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m881s\u001b[0m 6s/step - R2Score: -0.1403 - loss: 269577.2812 - mae: 269577.2812\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 6s/step - R2Score: -0.1194 - loss: 274938.7500 - mae: 274938.7500\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 6s/step - R2Score: -0.1388 - loss: 274809.9375 - mae: 274809.9375\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 6s/step - R2Score: -0.1175 - loss: 270367.2188 - mae: 270367.2188\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 6s/step - R2Score: -0.1229 - loss: 273640.3438 - mae: 273640.3438\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 6s/step - R2Score: -0.1050 - loss: 271972.4375 - mae: 271972.4375\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 6s/step - R2Score: -0.1285 - loss: 275231.9062 - mae: 275231.9062\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 6s/step - R2Score: -0.1189 - loss: 272300.3438 - mae: 272300.3438\n",
      "Training Resnet NN\n",
      "Epoch 1/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1413s\u001b[0m 10s/step - R2Score: -3.6534 - loss: 693980.4375 - mae: 693980.4375\n",
      "Epoch 2/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1295s\u001b[0m 10s/step - R2Score: -3.4377 - loss: 704038.8125 - mae: 704038.8125\n",
      "Epoch 3/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1292s\u001b[0m 10s/step - R2Score: -3.2543 - loss: 667075.8125 - mae: 667075.8125\n",
      "Epoch 4/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 10s/step - R2Score: -3.3085 - loss: 644868.9375 - mae: 644868.9375\n",
      "Epoch 5/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 10s/step - R2Score: -2.7496 - loss: 600598.3125 - mae: 600598.3125\n",
      "Epoch 6/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 10s/step - R2Score: -2.1890 - loss: 541628.5625 - mae: 541628.5625\n",
      "Epoch 7/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1288s\u001b[0m 10s/step - R2Score: -1.3643 - loss: 442958.4688 - mae: 442958.4688\n",
      "Epoch 8/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1292s\u001b[0m 10s/step - R2Score: -0.7453 - loss: 357800.5312 - mae: 357800.5312\n",
      "Epoch 9/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 10s/step - R2Score: -0.1475 - loss: 268221.1562 - mae: 268221.1562\n",
      "Epoch 10/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1285s\u001b[0m 10s/step - R2Score: 0.0073 - loss: 255564.3125 - mae: 255564.3125\n",
      "Epoch 11/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 10s/step - R2Score: 0.0423 - loss: 247279.8125 - mae: 247279.8125\n",
      "Epoch 12/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 10s/step - R2Score: 0.0430 - loss: 246218.3906 - mae: 246218.3906\n",
      "Epoch 13/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1321s\u001b[0m 10s/step - R2Score: 0.0745 - loss: 252684.6250 - mae: 252684.6250\n",
      "Epoch 14/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1309s\u001b[0m 10s/step - R2Score: 0.0799 - loss: 239555.4062 - mae: 239555.4062\n",
      "Epoch 15/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1298s\u001b[0m 10s/step - R2Score: 0.0885 - loss: 231117.6875 - mae: 231117.6875\n",
      "Epoch 16/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1328s\u001b[0m 10s/step - R2Score: 0.0731 - loss: 240659.7656 - mae: 240659.7656\n",
      "Epoch 17/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 10s/step - R2Score: 0.1210 - loss: 235949.2344 - mae: 235949.2344\n",
      "Epoch 18/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1314s\u001b[0m 10s/step - R2Score: 0.1212 - loss: 240958.1250 - mae: 240958.1250\n",
      "Epoch 19/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1298s\u001b[0m 10s/step - R2Score: 0.1165 - loss: 240675.5938 - mae: 240675.5938\n",
      "Epoch 20/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1293s\u001b[0m 10s/step - R2Score: 0.1458 - loss: 235194.2031 - mae: 235194.2031\n",
      "Epoch 21/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 10s/step - R2Score: 0.1397 - loss: 238965.3125 - mae: 238965.3125\n",
      "Epoch 22/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 10s/step - R2Score: 0.1523 - loss: 231263.3125 - mae: 231263.3125\n",
      "Epoch 23/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1289s\u001b[0m 10s/step - R2Score: 0.1694 - loss: 225881.2031 - mae: 225881.2031\n",
      "Epoch 24/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 10s/step - R2Score: 0.1928 - loss: 228786.8750 - mae: 228786.8750\n",
      "Epoch 25/25\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1342s\u001b[0m 11s/step - R2Score: 0.2079 - loss: 221956.9219 - mae: 221956.9219\n",
      "Comparison of Models for RealESRGAN_x4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN Base</th>\n",
       "      <td>305006</td>\n",
       "      <td>-0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet</th>\n",
       "      <td>514309</td>\n",
       "      <td>-1.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base Upscaled lanczos</th>\n",
       "      <td>305251</td>\n",
       "      <td>-0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet Upscaled lanczos</th>\n",
       "      <td>280873</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Base Upscaled RealESRGAN</th>\n",
       "      <td>313847</td>\n",
       "      <td>-0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN Resnet Upscaled RealESRGAN</th>\n",
       "      <td>448771</td>\n",
       "      <td>-0.618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MAE     R2\n",
       "Model                                       \n",
       "NN Base                        305006 -0.134\n",
       "NN Resnet                      514309 -1.551\n",
       "NN Base Upscaled lanczos       305251 -0.171\n",
       "NN Resnet Upscaled lanczos     280873  0.097\n",
       "NN Base Upscaled RealESRGAN    313847 -0.090\n",
       "NN Resnet Upscaled RealESRGAN  448771 -0.618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RealESRGAN\n",
    "# Load upscaled images\n",
    "X_train_upscale_RealESRGAN, y_train_upscale_RealESRGAN, X_test_upscale_RealESRGAN, y_test_upscale_RealESRGAN = load_upscale_data('RealESRGAN', \n",
    "                                                                                                                                   X_train_img, \n",
    "                                                                                                                                   X_test_img)\n",
    "\n",
    "# Create, Train and Evaluate the models\n",
    "nn_base_upscale_RealESRGAN = base_nn((311*scale, 415*scale, 3))\n",
    "nn_resnet_upscale_RealESRGAN = resnet_nn((311*scale, 415*scale, 3))\n",
    "\n",
    "# Debug\n",
    "print_shapes(X_train_upscale_RealESRGAN, y_train_upscale_RealESRGAN, X_test_upscale_RealESRGAN, y_test_upscale_RealESRGAN)\n",
    "assert_image_shapes_lst((311*scale, 415*scale, 3), X_train_upscale_RealESRGAN, X_test_upscale_RealESRGAN)\n",
    "\n",
    "print(\"Training Base NN\")\n",
    "_, _, nn_base_upscale_mae_RealESRGAN, nn_base_upscale_r2_RealESRGAN = train_and_evaluate_nn(nn_base_upscale_RealESRGAN, \n",
    "                                                                      X_train_upscale_RealESRGAN, y_train_upscale_RealESRGAN, \n",
    "                                                                      X_test_upscale_RealESRGAN, y_test_upscale_RealESRGAN)\n",
    "print(\"Training Resnet NN\")\n",
    "_, _, nn_resnet_upscale_mae_RealESRGAN, nn_resnet_upscale_r2_RealESRGAN = train_and_evaluate_nn(nn_resnet_upscale_RealESRGAN, \n",
    "                                                                                          X_train_upscale_RealESRGAN, y_train_upscale_RealESRGAN, \n",
    "                                                                                          X_test_upscale_RealESRGAN, y_test_upscale_RealESRGAN)\n",
    "\n",
    "# Store results for both models\n",
    "model_results.append((\"NN Base Upscaled \" + 'RealESRGAN', nn_base_upscale_mae_RealESRGAN, nn_base_upscale_r2_RealESRGAN))\n",
    "model_results.append((\"NN Resnet Upscaled \" + 'RealESRGAN', nn_resnet_upscale_mae_RealESRGAN, nn_resnet_upscale_r2_RealESRGAN))\n",
    "\n",
    "# Create a comparison of model results\n",
    "create_comparison(model_id, model_results)\n",
    "\n",
    "# Try to clear NN from memory\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
